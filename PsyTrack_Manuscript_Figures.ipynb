{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVzwz9MUgfbi"
   },
   "source": [
    "# _Extracting the Dynamics of Behavior in Decision-Making Experiments_\n",
    "## Figure Generator\n",
    "\n",
    "by Nicholas A. Roy $\\quad$  _(v1.1, last updated November 23, 2020)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ats61fugfbk"
   },
   "source": [
    "This notebook will precisely recreate all figures (Figures 1-8 and Supplementary Figures S1-8) from our manuscript _Extracting the Dynamics of Behavior in Decision-Making Experiments_. All figures will require the `PsyTrack` python package, as well as several other standard Python libraries. Figures requiring data will require that the corresponding dataset be downloaded and pre-processed. The necessary requirements for each figure are listed below, followed by instructions for downloading & preparing each of the three datasets:\n",
    " \n",
    " - Only the `PsyTrack` package is needed to produce the simulated data required for Figures 1, 2, S1, and S2\n",
    " \n",
    " - The IBL mouse dataset is required (as well as the `ONE Light` Python library) for Figures 3, 4, and S3-6\n",
    " \n",
    " - The Akrami rat dataset is required for Figures 5, 6, 8, and S7\n",
    " \n",
    " - The Akrami human subject dataset is required for Figures 7 and S8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PC-AFFuugfbl"
   },
   "source": [
    "A section with preliminary setup code is below, followed by code and instructions to load each dataset. There is then a section for each figure, with subsections for each subfigure. A few things to note:\n",
    "\n",
    " - **ALTERATIONS** | Many subfigures in the paper include some superficial additions done in Adobe Illustrator. Subfigures created purely inside Adobe illustrator (e.g. schematic figures) are noted.\n",
    " - **COMPUTE TIME** | While most individual `PsyTrack` models can be fit quickly, some figure require fitting dozens of models and so can take a relatively long time to compute. Subfigures which take longer than 90 seconds to produce are marked with an approximation of how long they ought to take.\n",
    " - **LOCAL STORAGE** | Many figures save the results of model fits to local storage, so figures can be retrieved and modified without having to refit the model each time. All the temporary files produced by the notebook are saved to the directory specified by the `SPATH` variable in the Preliminary setup section below. All temporary files plus all the subfigures saved should use under 500MB total. Note that if you are using a Colab hosted runtime, then anything saved to Colab local storage will disappear once the runtime expires (Colab has a 12 hour max). There is code to download all figures from Colab at the end of the notebook.\n",
    " - **SUBFIGURE DEPENDENCIES** | Occasionally, subfigures will depend upon the results of an earlier subfigure (usually part of the same figure) â€” a cell which fails to run may simply need an earlier cell to be run first (these instances should be clearly marked).\n",
    " - **SUBJECT-SPECIFIC DETAILS** | Many analyses run on an example subject should allow for other subjects to be easily swapped in, but some analyses may have subject-specific code that may impede this (i.e. hardcoded dates to extract certain sessions for analysis).\n",
    " - **VERSIONING** | Any additions, fixes, or changes made to this notebook will be noted in the versioning section at the very end of the notebook.\n",
    " \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VoDseNg1gfbl"
   },
   "source": [
    "# Preliminary setup and data retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGBQ_oIugfbm"
   },
   "source": [
    "Users will need to install the `PsyTrack` package (version 2.0), by running the cell below. We also define a variable `SPATH` which is the directory where all data files and figures produced by the notebook will be saved.\n",
    "\n",
    "Several standard Python packages are used: `numpy`, `scipy`, `matplotlib`, and `pandas`. We import all these libraries before proceeding, as well as setting several parameters in `matplotlib` to standardize the figures produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T10:04:43.698269Z",
     "start_time": "2020-04-23T10:04:40.446048Z"
    },
    "id": "QSa5tS2Ngfbn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Install then import PsyTrack\n",
    "!pip install psytrack==2.0\n",
    "import psytrack as psy\n",
    "\n",
    "# Set save path for all figures, decide whether to save permanently\n",
    "SPATH = \"Figures/\"\n",
    "!mkdir -p \"{SPATH}\"\n",
    "\n",
    "# Set matplotlib defaults for making files consistent in Illustrator\n",
    "colors = psy.COLORS\n",
    "zorder = psy.ZORDER\n",
    "plt.rcParams['figure.dpi'] = 140\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['savefig.facecolor'] = (1,1,1,0)\n",
    "plt.rcParams['savefig.bbox'] = \"tight\"\n",
    "plt.rcParams['font.size'] = 10\n",
    "# plt.rcParams['font.family'] = 'sans-serif'     # not available in Colab\n",
    "# plt.rcParams['font.sans-serif'] = 'Helvetica'  # not available in Colab\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 12\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2FqDWGYngfbs"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VB3VveZugfbs"
   },
   "source": [
    "## Download and pre-process IBL mouse data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWmLrfQAgfbt"
   },
   "source": [
    "1) Use the command below to instal the IBL's [ONE Light](https://github.com/int-brain-lab/ibllib/tree/master/oneibl) Python library, download the [IBL mouse behavior dataset](https://doi.org/10.6084/m9.figshare.11636748.v7) _(version 7, uploaded February 7, 2020)_ to our `SPATH` directory as `ibl-behavior-data-Dec2019.zip`, and unzip the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:17:34.515838Z",
     "start_time": "2020-04-18T01:17:34.476422Z"
    },
    "id": "SomAMEKhgfbu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: wget\n",
      "unzip:  cannot find or open Figures/ibl-behavior-data-Dec2019.zip, Figures/ibl-behavior-data-Dec2019.zip.zip or Figures/ibl-behavior-data-Dec2019.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "#!pip install ibllib\n",
    "!wget -nc -O \"{SPATH}ibl-behavior-data-Dec2019.zip\" \"https://ndownloader.figshare.com/files/21623715\"\n",
    "!unzip -d \"{SPATH}\" -n \"{SPATH}ibl-behavior-data-Dec2019.zip\"\n",
    "#clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mqj3mF1sgfbx"
   },
   "source": [
    "2) Use the [ONE Light](https://github.com/int-brain-lab/ibllib/tree/master/oneibl) library to build a table of all the subject and session data contained within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:18:08.044366Z",
     "start_time": "2020-04-18T01:17:36.492208Z"
    },
    "id": "eoXYyz62gfby",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Figures/ibl-behavioral-data-Dec2019'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d8576f30278e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mibl_data_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSPATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'ibl-behavioral-data-Dec2019'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcurrent_cwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mibl_data_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Search all sessions that have these dataset types.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Figures/ibl-behavioral-data-Dec2019'"
     ]
    }
   ],
   "source": [
    "from oneibl.onelight import ONE\n",
    "\n",
    "ibl_data_path = SPATH + 'ibl-behavioral-data-Dec2019'\n",
    "current_cwd = os.getcwd()\n",
    "os.chdir(ibl_data_path)\n",
    "\n",
    "# Search all sessions that have these dataset types.\n",
    "required_vars = ['_ibl_trials.choice', '_ibl_trials.contrastLeft',\n",
    "                 '_ibl_trials.contrastRight','_ibl_trials.feedbackType']\n",
    "one = ONE()\n",
    "eids = one.search(required_vars)\n",
    "\n",
    "mouseData = pd.DataFrame()\n",
    "for eid in eids:\n",
    "    lab, _, subject, date, session = eid.split(\"/\")    \n",
    "    sess_vars = {\n",
    "        \"eid\": eid,\n",
    "        \"lab\": lab,\n",
    "        \"subject\": subject,\n",
    "        \"date\": date,\n",
    "        \"session\": session,\n",
    "    }\n",
    "    mouseData = mouseData.append(sess_vars, sort=True, ignore_index=True)\n",
    "\n",
    "os.chdir(current_cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mouseData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDOOSP3ggfb4"
   },
   "source": [
    "3) Next, we use the table of session data to process the raw trial data below into a single CSV file, `ibl_processed.csv`, saved to our `SPATH` directory.\n",
    "\n",
    "There are several known anomalies in the raw data:\n",
    " - CSHL_002 codes left contrasts as negative right contrasts on 81 trials (these trials are corrected)\n",
    " - ZM_1084 has `feedbackType` of 0 for 3 trials (these trials are omitted)\n",
    " - DY_009, DY_010, DY_011 each have <5000 trials total (no adjustment)\n",
    " - ZM_1367, ZM_1369, ZM_1371, ZM_1372, and ZM_1743 are shown non-standard contrast values of 0.04 and 0.08 (no adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:19:44.870215Z",
     "start_time": "2020-04-18T01:18:08.047871Z"
    },
    "id": "xZVDIrTkgfb5"
   },
   "outputs": [],
   "source": [
    "all_vars = [\"contrastLeft\", \"contrastRight\", \"choice\", \"feedbackType\", \"probabilityLeft\"]\n",
    "df = pd.DataFrame()\n",
    "\n",
    "all_mice = []\n",
    "for j, s in enumerate(mouseData[\"subject\"].unique()):\n",
    "    print(\"\\rProcessing \" + str(j+1) + \" of \" + str(len(mouseData[\"subject\"].unique())), end=\"\")\n",
    "    mouse = mouseData[mouseData[\"subject\"]==s].sort_values(['date', 'session']).reset_index()\n",
    "    for i, row in mouse.iterrows():\n",
    "        myVars = {}\n",
    "        for v in all_vars:\n",
    "            filename = \"_ibl_trials.\" + v + \".npy\"\n",
    "            var_file = os.path.join(ibl_data_path, row.eid, \"alf\", filename)\n",
    "            myVars[v] = list(np.load(var_file).flatten())\n",
    "\n",
    "        num_trials = len(myVars[v])\n",
    "        myVars['lab'] = [row.lab]*num_trials\n",
    "        myVars['subject'] = [row.subject]*num_trials\n",
    "        myVars['date'] = [row.date]*num_trials\n",
    "        myVars['session'] = [row.session]*num_trials\n",
    "\n",
    "        all_mice += [pd.DataFrame(myVars, columns=myVars.keys())]\n",
    "        \n",
    "df = pd.concat(all_mice, ignore_index=True)\n",
    "\n",
    "df = df[df['choice'] != 0]        # dump mistrials\n",
    "df = df[df['feedbackType'] != 0]  # 3 anomalous trials from ZM_1084, omit\n",
    "df.loc[np.isnan(df['contrastLeft']), \"contrastLeft\"] = 0\n",
    "df.loc[np.isnan(df['contrastRight']), \"contrastRight\"] = 0\n",
    "df.loc[df[\"contrastRight\"] < 0, \"contrastLeft\"] = np.abs(df.loc[df[\"contrastRight\"] < 0, \"contrastRight\"])\n",
    "df.loc[df[\"contrastRight\"] < 0, \"contrastRight\"] = 0  # 81 anomalous trials in CSHL_002, correct\n",
    "df[\"answer\"] = df[\"feedbackType\"] * df[\"choice\"]      # new column to indicate correct answer\n",
    "df.loc[df[\"answer\"]==1, \"answer\"] = 0\n",
    "df.loc[df[\"answer\"]==-1, \"answer\"] = 1\n",
    "df.loc[df[\"feedbackType\"]==-1, \"feedbackType\"] = 0\n",
    "df.loc[df[\"choice\"]==1, \"choice\"] = 0\n",
    "df.loc[df[\"choice\"]==-1, \"choice\"] = 1\n",
    "df.to_csv(SPATH+\"ibl_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdDIQpC6gfb_"
   },
   "source": [
    "4) Next we run a few sanity checks on our data, to make sure everything processed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:19:45.504667Z",
     "start_time": "2020-04-18T01:19:44.873131Z"
    },
    "id": "UONTFii8gfb_"
   },
   "outputs": [],
   "source": [
    "print(\"contrastLeft: \", np.unique(df['contrastLeft']))   # [0, 0.0625, 0.125, 0.25, 0.5, 1.0] and [0.04, 0.08]\n",
    "print(\"contrastRight: \", np.unique(df['contrastRight'])) # [0, 0.0625, 0.125, 0.25, 0.5, 1.0] and [0.04, 0.08]\n",
    "print(\"choice: \", np.unique(df['choice']))               # [0, 1]\n",
    "print(\"feedbackType: \", np.unique(df['feedbackType']))   # [0, 1]\n",
    "print(\"answer: \", np.unique(df['answer']))               # [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVDFZXBogfcE"
   },
   "source": [
    "5) Finally, we define a function `getMouse` that extracts the data for a single mouse from our CSV file, and returns it as a PsyTrack compatible `dict`. We will use this function to access IBL mouse data in the figures below. Note the keyword argument and default value $p=5$ which controls the strength of the $\\tanh$ transformation on the contrast values. See Figure S4 and the STAR Methods of the accompanying paper for more details.\n",
    "\n",
    "**Note:** Once steps 1-5 have been run once, only step 5 will need to be run on subsequent uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:19:48.906769Z",
     "start_time": "2020-04-18T01:19:45.508884Z"
    },
    "id": "uC-l-HP_gfcF"
   },
   "outputs": [],
   "source": [
    "ibl_mouse_data_path = SPATH + \"ibl_processed.csv\"\n",
    "\n",
    "MOUSE_DF = pd.read_csv(ibl_mouse_data_path)\n",
    "def getMouse(subject, p=5):\n",
    "    df = MOUSE_DF[MOUSE_DF['subject']==subject]   # Restrict data to the subject specified\n",
    "    \n",
    "    cL = np.tanh(p*df['contrastLeft'])/np.tanh(p)   # tanh transformation of left contrasts\n",
    "    cR = np.tanh(p*df['contrastRight'])/np.tanh(p)  # tanh transformation of right contrasts\n",
    "    inputs = dict(cL = np.array(cL)[:, None], cR = np.array(cR)[:, None])\n",
    "\n",
    "    dat = dict(\n",
    "        subject=subject,\n",
    "        lab=np.unique(df[\"lab\"])[0],\n",
    "        contrastLeft=np.array(df['contrastLeft']),\n",
    "        contrastRight=np.array(df['contrastRight']),\n",
    "        date=np.array(df['date']),\n",
    "        dayLength=np.array(df.groupby(['date','session']).size()),\n",
    "        correct=np.array(df['feedbackType']),\n",
    "        answer=np.array(df['answer']),\n",
    "        probL=np.array(df['probabilityLeft']),\n",
    "        inputs = inputs,\n",
    "        y = np.array(df['choice'])\n",
    "    )\n",
    "    \n",
    "    return dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oi6Sc1n8gfcJ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goNXR7VYgfcJ"
   },
   "source": [
    "## Download and pre-process Akrami rat data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9-mLFgzgfcK"
   },
   "source": [
    "1) Download the [Akrami rat behavior dataset](https://doi.org/10.6084/m9.figshare.12213671.v1) _(version 1, uploaded May 18, 2020)_ to the `SPATH` directory as `rat_behavior.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPm05P0JslVq"
   },
   "outputs": [],
   "source": [
    "!wget -nc -O \"{SPATH}rat_behavior.csv\" \"https://ndownloader.figshare.com/files/22461707\"\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2u1GvUL1jjp"
   },
   "source": [
    "2) Sessions in the data corresponding to early shaping stages will be omitted, as will all mistrials (see the dataset's README for more info). The `getRat` function will then load a particular rat into a PsyTrack compatible `dict`.\n",
    "\n",
    "`getRat` has two optional parameters: `first` which will return a data set with only the first `first` trials (the default of 20,000 works for all analyses); `cutoff` excludes sessions with fewer than `cutoff` valid trials (default set to 50). We will use this function to access Akrami rat data in the figures below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:19:58.436964Z",
     "start_time": "2020-04-18T01:19:56.236185Z"
    },
    "id": "kcbHUY2tgfcn"
   },
   "outputs": [],
   "source": [
    "akrami_rat_data_path = SPATH + \"rat_behavior.csv\"\n",
    "\n",
    "RAT_DF = pd.read_csv(akrami_rat_data_path)\n",
    "RAT_DF = RAT_DF[RAT_DF[\"training_stage\"] > 2]  # Remove trials from early training\n",
    "RAT_DF = RAT_DF[~np.isnan(RAT_DF[\"choice\"])]   # Remove mistrials\n",
    "def getRat(subject, first=20000, cutoff=50):\n",
    "\n",
    "    df = RAT_DF[RAT_DF['subject_id']==subject]  # restrict dataset to single subject\n",
    "    df = df[:first]  # restrict to \"first\" trials of data\n",
    "    # remove sessions with fewer than \"cutoff\" valid trials\n",
    "    df = df.groupby('session').filter(lambda x: len(x) >= cutoff)   \n",
    "\n",
    "    # Normalize the stimuli to standard normal\n",
    "    s_a = (df[\"s_a\"] - np.mean(df[\"s_a\"]))/np.std(df[\"s_a\"])\n",
    "    s_b = (df[\"s_b\"] - np.mean(df[\"s_b\"]))/np.std(df[\"s_b\"])\n",
    "    \n",
    "    # Determine which trials do not have a valid previous trial (mistrial or session boundary)\n",
    "    t = np.array(df[\"trial\"])\n",
    "    prior = ((t[1:] - t[:-1]) == 1).astype(int)\n",
    "    prior = np.hstack(([0], prior))\n",
    "\n",
    "    # Calculate previous average tone value\n",
    "    s_avg = (df[\"s_a\"][:-1] + df[\"s_b\"][:-1])/2\n",
    "    s_avg = (s_avg - np.mean(s_avg))/np.std(s_avg)\n",
    "    s_avg = np.hstack(([0], s_avg))\n",
    "    s_avg = s_avg * prior  # for trials without a valid previous trial, set to 0\n",
    "\n",
    "    # Calculate previous correct answer\n",
    "    h = (df[\"correct_side\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
    "    h = np.hstack(([0], h))\n",
    "    h = h * prior  # for trials without a valid previous trial, set to 0\n",
    "    \n",
    "    # Calculate previous choice\n",
    "    c = (df[\"choice\"][:-1] * 2 - 1).astype(int)   # map from (0,1) to (-1,1)\n",
    "    c = np.hstack(([0], c))\n",
    "    c = c * prior  # for trials without a valid previous trial, set to 0\n",
    "    \n",
    "    inputs = dict(s_a = np.array(s_a)[:, None],\n",
    "                  s_b = np.array(s_b)[:, None],\n",
    "                  s_avg = np.array(s_avg)[:, None],\n",
    "                  h = np.array(h)[:, None],\n",
    "                  c = np.array(c)[:, None])\n",
    "\n",
    "    dat = dict(\n",
    "        subject = subject,\n",
    "        inputs = inputs,\n",
    "        s_a = np.array(df['s_a']),\n",
    "        s_b = np.array(df['s_b']),\n",
    "        correct = np.array(df['hit']),\n",
    "        answer = np.array(df['correct_side']),\n",
    "        y = np.array(df['choice']),\n",
    "        dayLength=np.array(df.groupby(['session']).size()),\n",
    "    )\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EI9GPcdLgfcq"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StmsyvQsgfcq"
   },
   "source": [
    "## Download and pre-process Akrami human subject data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCDDDY5Vgfcr"
   },
   "source": [
    "1) Download the [Akrami human subject behavior dataset](https://doi.org/10.6084/m9.figshare.12213671.v1) _(version 1, uploaded May 18, 2020)_. See the dataset's README for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO5rg5Rw262N"
   },
   "outputs": [],
   "source": [
    "!wget -nc -O \"{SPATH}human_auditory.csv\" \"https://ndownloader.figshare.com/files/22461695\"\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4KN65Oe279h"
   },
   "source": [
    "2) We define a function `getHuman` that extracts the data for a single human subject from the downloaded CSV file, and returns it in a PsyTrack compatible `dict`. We will use this function to access Akrami human subject data in the figures below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:20:03.756258Z",
     "start_time": "2020-04-18T01:20:03.660818Z"
    },
    "id": "jXxcPbFkgfcs"
   },
   "outputs": [],
   "source": [
    "akrami_human_data_path = SPATH + \"human_auditory.csv\"\n",
    "\n",
    "HUMAN_DF = pd.read_csv(akrami_human_data_path)\n",
    "def getHuman(subject):\n",
    "    \n",
    "    df = HUMAN_DF[HUMAN_DF['subject_id']==subject]\n",
    "    \n",
    "    s_a = (df[\"s_a\"] - np.mean(df[\"s_a\"]))/np.std(df[\"s_a\"])\n",
    "    s_b = (df[\"s_b\"] - np.mean(df[\"s_b\"]))/np.std(df[\"s_b\"])\n",
    "    \n",
    "    s_avg = (df[\"s_a\"][:-1] + df[\"s_b\"][:-1])/2\n",
    "    s_avg = (s_avg - np.mean(s_avg))/np.std(s_avg)\n",
    "    s_avg = np.hstack(([0], s_avg))\n",
    "    \n",
    "    inputs = dict(s_a = np.array(s_a)[:, None],\n",
    "                  s_b = np.array(s_b)[:, None],\n",
    "                  s_avg = np.array(s_avg)[:, None])\n",
    "\n",
    "    dat = dict(\n",
    "        subject = subject,\n",
    "        inputs = inputs,\n",
    "        s_a = np.array(df['s_a']),\n",
    "        s_b = np.array(df['s_b']),\n",
    "        correct = np.array(df['reward']),\n",
    "        answer = np.array(df['correct_side']),\n",
    "        y = np.array(df['choice'])\n",
    "    )\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9nWJYRigfcu"
   },
   "source": [
    "# Figure 1 | Schematic of Psychometric Weight Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xs7KBSawgfcv"
   },
   "source": [
    "**(A)** IBL task schematic (Illustrator only)\n",
    "\n",
    "**(B)** Example inputs (Illustrator only)\n",
    "\n",
    "**(C)** Schematic weight trajectories using regressors in (B)\n",
    "\n",
    "**(D)** Psychometric curves produced from weights from (C) at different points in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z49XZ7EIgfcv"
   },
   "source": [
    "## Figure 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:20:47.609533Z",
     "start_time": "2020-04-18T01:20:47.155907Z"
    },
    "id": "s-SYvwAfgfcw"
   },
   "outputs": [],
   "source": [
    "# Fig 1b â€” generate schematic weight trajectories\n",
    "def sigmoid(lenx, bias, slope):\n",
    "    x = np.arange(lenx)\n",
    "    return 1.0/(1.0 + np.exp(-(x-bias)/slope))\n",
    "\n",
    "x = np.arange(10000)\n",
    "bias_w = 0.8*sigmoid(10000, 6000, 1500)[::-1] - 0.08\n",
    "sL_w = -sigmoid(10000, 5000, 700) + 0.05\n",
    "sR_w = sigmoid(10000, 6500, 800) - 0.1\n",
    "\n",
    "gain = 4\n",
    "w = gain*np.vstack((bias_w,sL_w,sR_w))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(3.5,1.2))\n",
    "plt.plot(x, w[0], c=colors['bias'], lw=2)\n",
    "plt.plot(x, w[1], c=colors['sL'], lw=2)\n",
    "plt.plot(x, w[2], c=colors['sR'], lw=2)\n",
    "\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", alpha=0.5, zorder=0)\n",
    "\n",
    "plt.xticks([]); plt.yticks([0])\n",
    "plt.gca().set_yticklabels([0])\n",
    "plt.xlim(0,10000); plt.ylim(-1.02*gain,1.02*gain)\n",
    "# plt.xlabel(\"Trials\"); plt.ylabel(\"Weights\")\n",
    "\n",
    "# hand pick divider lines to make the Illustrator plot look nice\n",
    "xs = [1270,4975,8690]\n",
    "for x in xs:\n",
    "    plt.axvline(x, color=\"gray\", lw=2, alpha=0.0)\n",
    "    \n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False) \n",
    "\n",
    "# this makes the plot itself reflect the figsize, excluding the axis labels and ticks\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig1c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g86S8IL2gfcy"
   },
   "source": [
    "## Figure 1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:20:51.843072Z",
     "start_time": "2020-04-18T01:20:51.430171Z"
    },
    "id": "vLrHM1PHgfcz"
   },
   "outputs": [],
   "source": [
    "# Fig 1c â€” generate psychmoetric curves corresponding to weights at various times\n",
    "def generate_psych(w,x):\n",
    "    xL = x.copy(); xR = x.copy()\n",
    "    xL[xL>0] = 0; xR[xR<0] = 0\n",
    "    xL = np.abs(xL)\n",
    "    \n",
    "    wx = w[0] + xL*w[1] + xR*w[2]\n",
    "    pR = 1/(1+np.exp(-wx))\n",
    "    return pR\n",
    "\n",
    "# Generate psychometric curve for each time point in xs\n",
    "for i,cut in enumerate(xs):\n",
    "\n",
    "    x = np.arange(-1,1.01,.01)\n",
    "    pR = generate_psych(w[:,cut],x)\n",
    "    \n",
    "    x_dot = np.array([-1.0,-0.5,0.0,0.5,1.0])\n",
    "    pR_dot = generate_psych(w[:,cut],x_dot)\n",
    "\n",
    "    plt.figure(figsize=(1.25,1))\n",
    "    plt.plot(x*100, pR*100, color=\"black\", lw=1.5)\n",
    "    plt.plot(x_dot*100, pR_dot*100, color=\"black\", marker='o', lw=0, markersize=4)\n",
    "\n",
    "    # Grid lines\n",
    "    plt.axvline(  0, color=\"black\", linestyle=\"-\", alpha=0.1)\n",
    "    plt.axhline( 50, color=\"black\", linestyle=\"-\", alpha=0.1)\n",
    "    \n",
    "    plt.xticks([-100,-50,0,50,100]); plt.yticks([0,50,100])\n",
    "    plt.gca().set_xticklabels([]); plt.gca().set_yticklabels([])\n",
    "    plt.xlim(-110,110); plt.ylim(0,100)\n",
    "#     plt.xlabel(\"Right - Left Contrast (%)\"); plt.ylabel(\"Prob. Left (%)\")\n",
    "    \n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "    plt.savefig(SPATH + \"Fig1d_\"+str(i)+\".pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQ-JO6xagfc2"
   },
   "source": [
    "# Figure 2 | Recovering Psychometric Weights from Simulated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rlz7aWNsgfc3"
   },
   "source": [
    "**(A)** $K=4$ simulated weights of different sigma for $N=5000$ trials, with recovery showing 95% credible interval\n",
    "\n",
    "**(B)** Show the recovery for each sigma in (A), with 95% credible interval\n",
    "\n",
    "**(C)** 3 simulated weights as in (A), except with $\\sigma_{\\text{Day}}$  \n",
    "\n",
    "**(D)** Show the recovery for hyperparameters in (C), as in (B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grMdVjPfgfc4"
   },
   "source": [
    "## Figure 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:21:23.652294Z",
     "start_time": "2020-04-18T01:21:23.599016Z"
    },
    "id": "9preesL9gfc4"
   },
   "outputs": [],
   "source": [
    "# Fig 2a â€” generate simulated weights and recover with errorbars\n",
    "# Simulate\n",
    "seed = 31  # paper uses 31\n",
    "num_weights = 4\n",
    "num_trials = 5000\n",
    "hyper = {'sigma'   : 2**np.array([-4.0,-5.0,-6.0,-7.0]),\n",
    "         'sigInit' : 2**np.array([ 0.0, 0.0, 0.0, 0.0])}\n",
    "\n",
    "# Compute\n",
    "gen = psy.generateSim(K=num_weights, N=num_trials, hyper=hyper,\n",
    "                      boundary=6.0, iterations=1, seed=seed, savePath=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:22:20.042274Z",
     "start_time": "2020-04-18T01:21:24.430418Z"
    },
    "id": "9N2ywbjsgfc8"
   },
   "outputs": [],
   "source": [
    "# Recovery\n",
    "rec = psy.recoverSim(gen)\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig2a_data.npz', rec=rec, gen=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:22:20.955598Z",
     "start_time": "2020-04-18T01:22:20.045791Z"
    },
    "id": "Kz1SsURpgfdA"
   },
   "outputs": [],
   "source": [
    "# Reload data\n",
    "rec = np.load(SPATH+'fig2a_data.npz', allow_pickle=True)['rec'].item()\n",
    "gen = np.load(SPATH+'fig2a_data.npz', allow_pickle=True)['gen'].item()\n",
    "\n",
    "# Plotting\n",
    "sim_colors = [colors['bias'], colors['s1'], colors['s2'], colors['s_avg']]\n",
    "fig = plt.figure(figsize=(3.75,1.4))\n",
    "for i, c in enumerate(sim_colors):\n",
    "    plt.plot(gen['W'][:,i], c=c, lw=0.5, zorder=2*i)\n",
    "    plt.plot(rec['wMode'][i], c=c, lw=1, linestyle='--', alpha=0.5, zorder=2*i+1)\n",
    "    plt.fill_between(np.arange(num_trials),\n",
    "                     rec['wMode'][i] - 2 * rec['hess_info']['W_std'][i],\n",
    "                     rec['wMode'][i] + 2 * rec['hess_info']['W_std'][i],\n",
    "                     facecolor=c, alpha=0.2, zorder=2*i+1)\n",
    "\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=0.5, alpha=0.5, zorder=0)\n",
    "\n",
    "plt.xticks(1000*np.arange(0,6))\n",
    "plt.gca().set_xticklabels([0,1000,2000,3000,4000,5000])\n",
    "plt.yticks(np.arange(-4,5,2))\n",
    "\n",
    "plt.xlim(0,5000); plt.ylim(-4.3,4.3)\n",
    "# plt.xlabel(\"Trials\"); plt.ylabel(\"Weights\")\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig2a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfheuyCbgfdC"
   },
   "source": [
    "## Figure 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:22:22.107697Z",
     "start_time": "2020-04-18T01:22:20.958733Z"
    },
    "id": "37Xdf6p6gfdD"
   },
   "outputs": [],
   "source": [
    "# Reload data\n",
    "rec = np.load(SPATH+'fig2a_data.npz', allow_pickle=True)['rec'].item()\n",
    "\n",
    "# Plotting\n",
    "sim_colors = [colors['bias'], colors['s1'], colors['s2'], colors['s_avg']]\n",
    "plt.figure(figsize=(1.4,1.4))\n",
    "\n",
    "true_sigma = np.log2(rec['input']['sigma'])\n",
    "avg_sigma = np.log2(rec['hyp']['sigma'])\n",
    "err_sigma = rec['hess_info']['hyp_std']\n",
    "\n",
    "for i, c in enumerate(sim_colors):\n",
    "    plt.plot([i-0.3, i+0.3], [true_sigma[i]]*2, color=\"black\", linestyle=\"-\", lw=1.2, zorder=0)\n",
    "    plt.errorbar([i], avg_sigma[i], yerr=1.96*err_sigma[i], c=c, lw=1, marker='o', markersize=5)\n",
    "\n",
    "plt.xticks([0,1,2,3]); plt.yticks(np.arange(-8,-2))\n",
    "plt.xlim(-0.5,3.5); plt.ylim(-7.5,-3.5)\n",
    "\n",
    "plt.gca().set_xticklabels([r\"$\\sigma_1$\", r\"$\\sigma_2$\", r\"$\\sigma_3$\", r\"$\\sigma_4$\"])\n",
    "\n",
    "# plt.ylabel(r\"$\\log_2(\\sigma)$\")\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig2b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBkpetNAgfdG"
   },
   "source": [
    "## Figure 2c\n",
    "\n",
    "_2 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:22:30.507549Z",
     "start_time": "2020-04-18T01:22:30.451982Z"
    },
    "id": "Ku9em5AEgfdG"
   },
   "outputs": [],
   "source": [
    "# Fig 2c â€” generate simulated weights and recover with errorbars\n",
    "# Simulate\n",
    "seed = 102  # paper uses 102\n",
    "num_weights = 3\n",
    "num_trials = 5000\n",
    "hyper = {'sigma'   : 2**np.array([-4.5, -5.0,-16.0]),\n",
    "         'sigInit' : 2**np.array([ 0.0,  0.0,  0.0]),\n",
    "         'sigDay'  : 2**np.array([ 0.5,-16.0,  1.0])\n",
    "        }\n",
    "days = [500]*9\n",
    "\n",
    "# Compute\n",
    "gen = psy.generateSim(K=num_weights, N=num_trials, hyper=hyper, days=days,\n",
    "                      boundary=10.0, iterations=1, seed=seed, savePath=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:24:04.446435Z",
     "start_time": "2020-04-18T01:22:31.149855Z"
    },
    "id": "6CKzejNOgfdJ"
   },
   "outputs": [],
   "source": [
    "# Recovery\n",
    "rec = psy.recoverSim(gen)\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig2c_data.npz', rec=rec, gen=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:24:05.242522Z",
     "start_time": "2020-04-18T01:24:04.449465Z"
    },
    "id": "X5tkEDQSgfdL"
   },
   "outputs": [],
   "source": [
    "# Reload data\n",
    "rec = np.load(SPATH+'fig2c_data.npz', allow_pickle=True)['rec'].item()\n",
    "gen = np.load(SPATH+'fig2c_data.npz', allow_pickle=True)['gen'].item()\n",
    "\n",
    "# Plotting\n",
    "sim_colors = [colors['bias'], colors['s1'], colors['s2']]\n",
    "fig = plt.figure(figsize=(3.75,1.4))\n",
    "for i, c in enumerate(sim_colors):\n",
    "    plt.plot(gen['W'][:,i], c=c, lw=0.5, zorder=5-i)\n",
    "    plt.plot(rec['wMode'][i], c=c, lw=1, linestyle='--', alpha=0.5, zorder=5-i)\n",
    "    plt.fill_between(np.arange(num_trials),\n",
    "                     rec['wMode'][i] - 2 * rec['hess_info']['W_std'][i],\n",
    "                     rec['wMode'][i] + 2 * rec['hess_info']['W_std'][i],\n",
    "                     facecolor=c, alpha=0.2, zorder=5-i)\n",
    "\n",
    "for i in np.cumsum(days):\n",
    "    plt.axvline(i, color=\"black\", lw=0.5, alpha=0.5, zorder=0)\n",
    "    \n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=0.5, alpha=0.5, zorder=0)\n",
    "plt.xticks(1000*np.arange(0,6))\n",
    "plt.gca().set_xticklabels([0,1000,2000,3000,4000,5000])\n",
    "plt.yticks(np.arange(-4,5,2))\n",
    "\n",
    "plt.xlim(0,5000); plt.ylim(-4.3,4.3)\n",
    "# plt.xlabel(\"Trials\"); plt.ylabel(\"Weights\")\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig2c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7xT0AYogfdO"
   },
   "source": [
    "## Figure 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:24:06.049780Z",
     "start_time": "2020-04-18T01:24:05.245499Z"
    },
    "id": "baroICDmgfdP"
   },
   "outputs": [],
   "source": [
    "# Reload data\n",
    "rec = np.load(SPATH+'fig2c_data.npz', allow_pickle=True)['rec'].item()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(1.4,1.4))\n",
    "\n",
    "true_sigma = np.log2(rec['input']['sigma'])\n",
    "avg_sigma = np.log2(rec['hyp']['sigma'])\n",
    "err_sigma = rec['hess_info']['hyp_std'][:3]\n",
    "for i, c in enumerate(sim_colors):\n",
    "    plt.plot([2*i-0.3, 2*i+0.3], [true_sigma[i]]*2, color=\"black\", linestyle=\"-\", lw=1.2, zorder=0)\n",
    "    plt.errorbar([2*i], avg_sigma[i], yerr=1.96*err_sigma[i], c=c, lw=1, marker='o', markersize=5)\n",
    "\n",
    "true_sigma = np.log2(rec['input']['sigDay'])\n",
    "avg_sigma = np.log2(rec['hyp']['sigDay'])\n",
    "err_sigma = rec['hess_info']['hyp_std'][3:]\n",
    "for i, c in enumerate(sim_colors):\n",
    "    plt.plot([2*i-0.3+1, 2*i+0.3+1], [true_sigma[i]]*2, color=\"black\", linestyle=\"-\", lw=1.2, zorder=0)\n",
    "    plt.errorbar([2*i+1], avg_sigma[i], yerr=1.96*err_sigma[i], c=c, lw=1, marker='s', markersize=5)\n",
    "\n",
    "plt.axvspan(2.6,4.4, facecolor=\"black\", edgecolor=\"none\", alpha=0.1)\n",
    "plt.xticks(np.arange(6))\n",
    "plt.yticks([-8,-6,-4,-2,0,2])\n",
    "plt.gca().set_xticklabels([r\"$\\sigma_1$\", r\"$_{day}$\",\n",
    "                           r\"$\\sigma_2$\", r\"$_{day}$\",\n",
    "                           r\"$\\sigma_3$\", r\"$_{day}$\",])\n",
    "plt.xlim(-0.5,5.5); plt.ylim(-8.5,2.5)\n",
    "# plt.ylabel(r\"$\\log_2(\\sigma)$\")\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig2d.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5yKnakcgfdR"
   },
   "source": [
    "# Figure 3 | Visualization of Early Learning in IBL Mice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uc5xmlMVgfdS"
   },
   "source": [
    "**(A)** A performance curve of an example mouse (`CSHL_003`) on easy trials during early training\n",
    "\n",
    "**(B)** Psychometric weights for the mouse and sessions shown in (A)\n",
    "\n",
    "**(C)** The performance curves of a subset (1 in 8) of the full population of mice on easy trials in early training (first 16 sessions)\n",
    "\n",
    "**(D)** Psychometric weights for all the mice shown in (C), plus average weights calculated from all mice in the population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T07:22:32.432229Z",
     "start_time": "2020-01-23T07:22:32.387441Z"
    },
    "id": "HHb50rthgfdS"
   },
   "source": [
    "## Figure 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:24:33.814622Z",
     "start_time": "2020-04-18T01:24:32.012976Z"
    },
    "id": "SV7bAClvgfdT"
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "outData = getMouse('CSHL_003', 5)\n",
    "easy_trials = (outData['contrastLeft'] > 0.45).astype(int) | (outData['contrastRight'] > 0.45).astype(int)\n",
    "\n",
    "perf = []\n",
    "for d in np.unique(outData['date']):\n",
    "    date_trials = (outData['date'] == d).astype(int)\n",
    "    inds = (date_trials * easy_trials).astype(bool)\n",
    "    perf += [np.average(outData['correct'][inds])]\n",
    "\n",
    "dates = np.unique([datetime.strptime(i, \"%Y-%m-%d\") for i in outData['date']])\n",
    "dates = np.arange(len(dates)) + 1\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(2.75,0.9))\n",
    "\n",
    "plt.plot(dates[:16], perf[:16], color=\"black\", linewidth=1.5, zorder=2)\n",
    "plt.scatter(dates[9], perf[9], c=\"white\", s=30, edgecolors=\"black\", linestyle=\"--\", lw=0.75, zorder=5, alpha=1)\n",
    "\n",
    "plt.axhline(0.5, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
    "\n",
    "plt.xticks(np.arange(0,16,5))\n",
    "plt.yticks([0.4,0.6,0.8,1.0])\n",
    "plt.ylim(0.25,1.0)\n",
    "plt.xlim(1, 15.5)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig3a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "heJGyBnPgfdW"
   },
   "source": [
    "## Figure 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:24:58.446636Z",
     "start_time": "2020-04-18T01:24:38.187152Z"
    },
    "id": "8_EacCqDgfdW"
   },
   "outputs": [],
   "source": [
    "# Collect data from manually determined training period\n",
    "new_dat = psy.trim(outData, END=7000)\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 0, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : None\n",
    "  }\n",
    "optList = ['sigma']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig3b_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:24:59.223528Z",
     "start_time": "2020-04-18T01:24:58.449959Z"
    },
    "id": "KueRXLwDgfdY"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'fig3b_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
    "\n",
    "plt.axvline(np.cumsum(dat['new_dat']['dayLength'])[8], c=\"black\", lw=1.5, ls=\"--\", zorder=15)\n",
    "plt.ylim(-5.3,5.3)\n",
    "plt.xlim(0, 6950)\n",
    "plt.yticks([-4,-2,0,2,4])\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig3b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IFbRzjjgfdb"
   },
   "source": [
    "## Figure 3c\n",
    "\n",
    "_2 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:26:40.808120Z",
     "start_time": "2020-04-18T01:25:09.451346Z"
    },
    "id": "kmsmdVxhgfdb"
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "all_dates = []\n",
    "all_perf = []\n",
    "for s in np.unique(MOUSE_DF['subject']):\n",
    "    outData = getMouse(s, 5)\n",
    "    easy_trials = (outData['contrastLeft'] > 0.45).astype(int) | (outData['contrastRight'] > 0.45).astype(int)\n",
    "\n",
    "    perf = []\n",
    "    for d in np.unique(outData['date']):\n",
    "        date_trials = (outData['date'] == d).astype(int)\n",
    "        inds = (date_trials * easy_trials).astype(bool)\n",
    "        perf += [np.average(outData['correct'][inds])]\n",
    "\n",
    "    dates = np.unique([datetime.strptime(i, \"%Y-%m-%d\") for i in outData['date']])\n",
    "    dates = np.arange(len(dates))\n",
    "    \n",
    "    all_dates += [dates]\n",
    "    all_perf += [perf]\n",
    "    \n",
    "x = [[] for i in range(25)]\n",
    "for dates, perf in zip(all_dates, all_perf):\n",
    "    for ind, d in enumerate(dates):\n",
    "        if d < 25:\n",
    "            x[d] += [perf[ind]]\n",
    "perf_avg = [np.average(i) for i in x] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:26:41.277035Z",
     "start_time": "2020-04-18T01:26:40.810891Z"
    },
    "id": "v2PCwuhdgfde"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2.75,0.9))\n",
    "\n",
    "for dates, perf in zip(all_dates[::8], all_perf[::8]):\n",
    "    plt.plot(dates[:25], perf[:25], color=\"black\", linewidth=1, alpha=0.2, zorder=1)\n",
    "\n",
    "plt.plot(perf_avg[:25], color=\"black\", lw=2.5, alpha=0.8, zorder=6)\n",
    "\n",
    "plt.axhline(0.5, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
    "\n",
    "plt.xticks(np.arange(0,16,5))\n",
    "plt.yticks([0.4,0.6,0.8,1.0])\n",
    "plt.ylim(0.25,1.0)\n",
    "plt.xlim(1, 15.5)\n",
    "plt.gca().set_yticklabels([])\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig3c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSHx0hK_gfdh"
   },
   "source": [
    "## Figure 3d\n",
    "_20 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:44:55.583172Z",
     "start_time": "2020-04-18T01:26:41.279989Z"
    },
    "id": "Z5caxLeWgfdh"
   },
   "outputs": [],
   "source": [
    "for i, s in enumerate(MOUSE_DF['subject']):\n",
    "\n",
    "    print(\"\\rProcessing \" + str(i+1) + \" of \" + str(len(MOUSE_DF['subject'].unique())), end=\"\")\n",
    "\n",
    "    outData = getMouse(s, 5)\n",
    "    \n",
    "    # Collect data from manually determined training period\n",
    "    new_dat = psy.trim(outData, END=7000)\n",
    "\n",
    "    # Compute\n",
    "    weights = {'bias' : 0, 'cL' : 1, 'cR' : 1}\n",
    "    K = np.sum([weights[i] for i in weights.keys()])\n",
    "    hyper_guess = {\n",
    "     'sigma'   : [2**-5]*K,\n",
    "     'sigInit' : 2**5,\n",
    "     'sigDay'  : None\n",
    "      }\n",
    "    optList = ['sigma']\n",
    "\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList, hess_calc=None)\n",
    "\n",
    "    dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'hess_info' : hess_info,\n",
    "           'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "    # Save interim result\n",
    "    np.savez_compressed(SPATH+'fig3c_'+s+'_data.npz', dat=dat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:44:57.266324Z",
     "start_time": "2020-04-18T01:44:55.585987Z"
    },
    "id": "9vP7uGz6gfdj",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2.75,1.3))\n",
    "w0 = []\n",
    "w1 = []\n",
    "for i, s in enumerate(np.unique(MOUSE_DF['subject'])):\n",
    "\n",
    "    dat = np.load(SPATH+'fig3c_'+s+'_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "    w0 += [np.hstack((dat['wMode'][0][:7000], [np.nan]*(7000 - len(dat['wMode'][0][:7000]))))]\n",
    "    w1 += [np.hstack((dat['wMode'][1][:7000], [np.nan]*(7000 - len(dat['wMode'][1][:7000]))))]\n",
    "\n",
    "    if not i%8:\n",
    "        plt.plot(dat['wMode'][0], color=colors['cL'], lw=1, alpha=0.2, zorder=4)\n",
    "        plt.plot(dat['wMode'][1], color=colors['cR'], lw=1, alpha=0.2, zorder=2)\n",
    "\n",
    "    \n",
    "plt.plot(np.nanmean(w0, axis=0), color=colors['cL'], lw=2.5, alpha=0.8, zorder=6)\n",
    "plt.plot(np.nanmean(w1, axis=0), color=colors['cR'], lw=2.5, alpha=0.8, zorder=6)\n",
    "plt.axhline(0, linestyle='--', color=\"black\", lw=1, alpha=0.5, zorder=0)\n",
    "plt.ylim(-5.3,5.3)\n",
    "plt.xlim(0, 6950)\n",
    "plt.yticks([-4,-2,0,2,4])\n",
    "plt.gca().set_yticklabels([])\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig3d.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAHhUULfgfdm"
   },
   "source": [
    "# Figure 4 | Adaptation to Bias Blocks in an Example IBL Mouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R1PKTl-5gfdm"
   },
   "source": [
    "**(A)** Show performance curve of example mouse on easy trials, highlight different training periods\n",
    "\n",
    "**(B)** Show data for early bias blocks of example mouse\n",
    "\n",
    "**(C)** Show data for late bias blocks of example mouse\n",
    "\n",
    "**(D)** For early bias blocks (B), chunk the bias weight by block, plot how the weight changes from start to end of each block\n",
    "\n",
    "**(E)** Same as (D) but for late bias blocks (C)\n",
    "\n",
    "**(F)** Overlay optimal bias weight on the 2nd session shown in (C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5lR5MiYgfdn"
   },
   "source": [
    "## Figure 4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:45:06.682753Z",
     "start_time": "2020-04-18T01:45:05.006787Z"
    },
    "id": "iZe0MFy3gfdn"
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "easy_trials = (outData['contrastLeft'] > 0.45).astype(int) | (outData['contrastRight'] > 0.45).astype(int)\n",
    "\n",
    "perf = []\n",
    "for d in np.unique(outData['date']):\n",
    "    date_trials = (outData['date'] == d).astype(int)\n",
    "    inds = (date_trials * easy_trials).astype(bool)\n",
    "    perf += [np.average(outData['correct'][inds])]\n",
    "\n",
    "dates = [datetime.strptime(i, \"%Y-%m-%d\") for i in outData['date']]\n",
    "dates = np.arange(len(dates)) + 1\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(3.5,0.9))\n",
    "plt.plot(dates[:52], perf[:52], color=\"black\", linewidth=1.5, zorder=2)\n",
    "\n",
    "plt.axhline(0.5, linestyle='--', color=\"black\", lw=1, alpha=0.5, zorder=1)\n",
    "plt.yticks([0.4,0.6,0.8,1.0])\n",
    "plt.ylim(0.25,1)\n",
    "plt.xlim(1,47)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "#plt.ylabel(\"Performance\\n(on easy trials)\")\n",
    "#plt.xlabel(\"Weeks of Training\")\n",
    "\n",
    "plt.axvspan(0,17.5, ymax=1,\n",
    "            edgecolor='None', alpha=0.1, facecolor=\"black\", zorder=0)\n",
    "plt.axvspan(16.5,19.5, linestyle=\"-\", lw=2.5, ymin=0.03, ymax=0.98,\n",
    "            edgecolor='#E32D91', alpha=.8, facecolor=\"None\", zorder=8)\n",
    "plt.axvspan(43.5,45.5, linestyle=\"-\", lw=2.5, ymin=0.03, ymax=0.98,\n",
    "            edgecolor='#9252AB', alpha=.8, facecolor=\"None\", zorder=9)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "# plt.savefig(SPATH + \"Fig4a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MISkYx9gfds"
   },
   "source": [
    "## Figure 4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:45:44.476264Z",
     "start_time": "2020-04-18T01:45:09.894803Z"
    },
    "id": "MDLG3Ochgfds"
   },
   "outputs": [],
   "source": [
    "# Collect data from manually determined training period\n",
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "_start  = np.where(outData['date'] >= '2019-03-21')[0][0]\n",
    "_end    = np.where(outData['date'] >= '2019-03-23')[0][0]\n",
    "new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "# Hardcode random trials where probL != 0.5 before bias blocks begin to 0.5\n",
    "# (fyi, this is due to anti-biasing in the IBL early training protocol)\n",
    "new_dat['probL'][:np.where(new_dat['date'] >= '2019-03-22')[0][0]] = 0.5\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**-5]*K\n",
    "  }\n",
    "optList = ['sigma', 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig4b_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:45:44.535995Z",
     "start_time": "2020-04-18T01:45:44.478715Z"
    },
    "id": "CDNppZ_8gfdx"
   },
   "outputs": [],
   "source": [
    "BIAS_COLORS = {50 : 'None', 20 : psy.COLORS['sR'], 80 : psy.COLORS['sL']}\n",
    "def addBiasBlocks(fig, pL):\n",
    "    plt.sca(fig.gca())\n",
    "    i = 0\n",
    "    while i < len(pL):\n",
    "        start = i\n",
    "        while i+1 < len(pL) and np.linalg.norm(pL[i] - pL[i+1]) < 0.0001:\n",
    "            i += 1\n",
    "        fc = BIAS_COLORS[int(100 * pL[start])]\n",
    "        plt.axvspan(start, i+1, facecolor=fc, alpha=0.2, edgecolor=None)\n",
    "        i += 1\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:45:45.273854Z",
     "start_time": "2020-04-18T01:45:44.540219Z"
    },
    "id": "ZvWzus2bgfdz"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'fig4b_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
    "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
    "\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.gca().set_yticks(np.arange(-6, 7,2))\n",
    "plt.ylim(-5.3,5.3)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig4b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iI3P1GZlgfd2"
   },
   "source": [
    "## Figure 4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:46:57.043289Z",
     "start_time": "2020-04-18T01:46:26.469282Z"
    },
    "id": "yqTvpd2Bgfd2"
   },
   "outputs": [],
   "source": [
    "# Collect data from manually determined training period\n",
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "_start  = np.where(outData['date'] >= '2019-04-30')[0][0]\n",
    "_end    = np.where(outData['date'] >= '2019-05-02')[0][0]\n",
    "new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**-5]*K\n",
    "  }\n",
    "optList = ['sigma', 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig4c_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:46:57.738587Z",
     "start_time": "2020-04-18T01:46:57.045770Z"
    },
    "id": "ljpEqBWegfd5"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'fig4c_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
    "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
    "\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.gca().set_yticks(np.arange(-6, 7,2))\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.ylim(-5.3,5.3)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig4c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnS7N25fgfd8"
   },
   "source": [
    "## Figure 4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:47:50.006569Z",
     "start_time": "2020-04-18T01:46:57.741749Z"
    },
    "id": "fZZyS8Q0gfd9"
   },
   "outputs": [],
   "source": [
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "\n",
    "# Collect data from manually determined training period\n",
    "_start  = np.where(outData['date'] >= '2019-03-22')[0][0]\n",
    "_end    = np.where(outData['date'] >= '2019-03-26')[0][0]\n",
    "new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "# Hardcode random trials where probL != 0.5 before bias begins to 0.5\n",
    "# (fyi, this is due to anti-biasing in the IBL early training protocol)\n",
    "new_dat['probL'][:np.where(new_dat['date'] >= '2019-03-22')[0][0]] = 0.5\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**-5]*K\n",
    "  }\n",
    "optList = ['sigma', 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig4d_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:47:50.732024Z",
     "start_time": "2020-04-18T01:47:50.010315Z"
    },
    "id": "mSFEQLBjgfd_"
   },
   "outputs": [],
   "source": [
    "def bias_diff(dat_load, figsize=(1.5,1.5)):\n",
    "    dat = np.load(dat_load, allow_pickle=True)['dat'].item()\n",
    "    pL = dat['new_dat']['probL']\n",
    "    pL_diff = pL[1:] - pL[:-1]\n",
    "    inds = np.where(pL_diff)[0]\n",
    "    start_inds = [0] + list(inds+1)\n",
    "    start_inds = [i for i in start_inds if (np.isclose(pL[i], 0.2) or np.isclose(pL[i], 0.8))]\n",
    "    end_inds = list(inds) + [len(pL)-1]\n",
    "    end_inds = [i for i in end_inds if (np.isclose(pL[i], 0.2) or np.isclose(pL[i], 0.8))]\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for s, e in zip(start_inds, end_inds):\n",
    "        if e-s < 20: continue\n",
    "        block_inds = np.arange(s, e+1)\n",
    "        block = dat['wMode'][0, block_inds] - dat['wMode'][0, s]\n",
    "        if np.isclose(pL[s], 0.2):\n",
    "            plt.plot(block, color=colors['cR'], alpha=0.8, zorder=2, lw=1)\n",
    "        else:\n",
    "            plt.plot(block, color=colors['cL'], alpha=0.8, zorder=4, lw=1)\n",
    "    \n",
    "    plt.axhline(0, linestyle='--', color=\"black\", lw=1, alpha=0.5, zorder=0)\n",
    "    plt.ylim(-5.5,5.5)\n",
    "    plt.xlim(0, 75)\n",
    "\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.subplots_adjust(0,0,1,1)\n",
    "    return fig\n",
    "\n",
    "fig = bias_diff(SPATH+'fig4d_data.npz', figsize=(1.3,1.3));\n",
    "plt.gca().set_yticks([-4,-2,0,2,4])\n",
    "plt.savefig(SPATH + \"Fig4d.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mhkc0tHOgfeB"
   },
   "source": [
    "## Figure 4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:54.924739Z",
     "start_time": "2020-04-18T01:47:50.735178Z"
    },
    "id": "9AF7CKazgfeB"
   },
   "outputs": [],
   "source": [
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "\n",
    "# Collect data from manually determined training period\n",
    "_start  = np.where(outData['date'] >= '2019-04-30')[0][0]\n",
    "_end    = np.where(outData['date'] >= '2019-05-03')[0][0]\n",
    "new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**-5]*K\n",
    "  }\n",
    "optList = ['sigma', 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig4e_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:55.574446Z",
     "start_time": "2020-04-18T01:48:54.927119Z"
    },
    "id": "xZTvGEdcgfeE"
   },
   "outputs": [],
   "source": [
    "fig = bias_diff(SPATH+'fig4e_data.npz', figsize=(1.3,1.3));\n",
    "plt.gca().set_yticks([-4,-2,0,2,4])\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.savefig(SPATH + \"Fig4e.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edqcfySmgfeH"
   },
   "source": [
    "## Figure 4f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:55.632958Z",
     "start_time": "2020-04-18T01:48:55.576832Z"
    },
    "id": "EKpMHbPFgfeH"
   },
   "outputs": [],
   "source": [
    "def max_bias(bias, side, wL, wR):\n",
    "        \n",
    "    contrasts = np.array([-1., -0.25, -0.125, -0.0625, 0., 0.0625, 0.125, 0.25, 1.])\n",
    "    \n",
    "    p=5\n",
    "    transformed_con = np.tanh(p*np.abs(contrasts))/np.tanh(p)\n",
    "\n",
    "    p_biasL = [.8/4.5]*4 + [1/9] + [.2/4.5]*4    \n",
    "    p_biasR = [.2/4.5]*4 + [1/9] + [.8/4.5]*4\n",
    "    p_biasM = [1/9]*9\n",
    "\n",
    "    w = [wL]*4 + [0] + [wR]*4\n",
    "    correct = [0]*4 + [0] + [1]*4\n",
    "\n",
    "    pL = 1 - (1/(1+np.exp(-(transformed_con*w + bias))))\n",
    "    pCorrect = np.abs(correct - pL)\n",
    "    \n",
    "    if side==\"L\":\n",
    "        pCorrect[4] = pL[4]*0.8 + (1-pL[4])*0.2\n",
    "        expval = np.sum(p_biasL * pCorrect)\n",
    "    \n",
    "    elif side==\"R\":\n",
    "        pCorrect[4] = pL[4]*0.2 + (1-pL[4])*0.8\n",
    "        expval = np.sum(p_biasR * pCorrect)\n",
    "    \n",
    "    elif side==\"M\":\n",
    "        pCorrect[4] = 0.5\n",
    "        expval = np.sum(p_biasM * pCorrect)\n",
    "    \n",
    "    return -expval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:57.445049Z",
     "start_time": "2020-04-18T01:48:55.637573Z"
    },
    "id": "gKSLfL5ggfeL"
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "dat = np.load(SPATH+'fig4c_data.npz', allow_pickle=True)['dat'].item()\n",
    "start = dat['new_dat']['dayLength'][0]\n",
    "\n",
    "optBias = []\n",
    "optReward = []\n",
    "for i in np.arange(start, dat['wMode'].shape[1]):\n",
    "    \n",
    "    if dat['new_dat']['probL'][i] < 0.21: side = 'R'\n",
    "    elif dat['new_dat']['probL'][i] > 0.79: side = 'L'\n",
    "    else: side = 'M'\n",
    "        \n",
    "    res = minimize(max_bias,[0], args=(side, dat['wMode'][1,i], dat['wMode'][2,i]))\n",
    "    optBias += [res.x]\n",
    "    optReward += [-res.fun]\n",
    "\n",
    "print(\"Avg. Reward:\", np.mean(optReward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:58.070451Z",
     "start_time": "2020-04-18T01:48:57.448083Z"
    },
    "id": "nkVwSTSUgfeO"
   },
   "outputs": [],
   "source": [
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"],\n",
    "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
    "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
    "\n",
    "plt.plot(np.arange(start, dat['wMode'].shape[1]), optBias, 'k-', lw=2, zorder=10)\n",
    "plt.gca().set_yticks(np.arange(-6, 7,2))\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.gca().set_xticks([750, 1000, 1250])\n",
    "plt.xlim(start, None); plt.ylim(-5.3,5.3)\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig4f.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:58.292918Z",
     "start_time": "2020-04-18T01:48:58.074129Z"
    },
    "id": "_EzFYonvgfeQ"
   },
   "outputs": [],
   "source": [
    "# Actual predicted reward using actual bias weight\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "optReward_pred = []\n",
    "optReward_0bias = []\n",
    "for i in np.arange(start, dat['wMode'].shape[1]):\n",
    "    \n",
    "    if dat['new_dat']['probL'][i] < 0.21: side = 'R'\n",
    "    elif dat['new_dat']['probL'][i] > 0.79: side = 'L'\n",
    "    else: side = 'M'\n",
    "        \n",
    "    optReward_pred += [-max_bias(dat['wMode'][0,i], side, dat['wMode'][1,i], dat['wMode'][2,i])]\n",
    "    optReward_0bias += [-max_bias(0.0, side, dat['wMode'][1,i], dat['wMode'][2,i])]\n",
    "\n",
    "print(\"Predicted Avg. Reward:\", np.mean(optReward_pred))\n",
    "print(\"No Bias Avg. Reward:\", np.mean(optReward_0bias))\n",
    "print(\"Empirical Avg. Reward:\", np.mean(dat['new_dat']['correct'][start:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWTR9owcgfeW"
   },
   "source": [
    "# Figure 5 | Visualization of Learning in an Example Akrami Rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91n_SNbVgfeW"
   },
   "source": [
    "**(A)** Akrami rat task schematic (Illustrator only)\n",
    "\n",
    "**(B)** Psychometric weights for an example rat (`W080`)\n",
    " \n",
    "**(C)** Compare model predictions to empirical choice behavior under various trial conditions, for a 500 trial window starting at trial 2000.\n",
    "\n",
    "**(D)** As in (C), starting at trial 6500\n",
    "\n",
    "**(E)** As in (C), starting at trial 11000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ohWyMHGgfeX"
   },
   "source": [
    "## Figure 5b\n",
    "\n",
    "_15 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T02:04:08.046571Z",
     "start_time": "2020-04-18T01:50:15.385773Z"
    },
    "id": "iXDZq3HkgfeX"
   },
   "outputs": [],
   "source": [
    "outData = getRat(\"W080\")\n",
    "new_dat = psy.trim(outData, START=0, END=12500)\n",
    "\n",
    "weights = {'bias': 1, 's_a': 1, 's_b': 1, 'h': 1, 'c': 1, \"s_avg\": 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**-4]*K,\n",
    "  }\n",
    "optList = ['sigma', 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig5b_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T02:04:09.643751Z",
     "start_time": "2020-04-18T02:04:08.049537Z"
    },
    "id": "5CneCsBugfeZ"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'fig5b_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(4.75,1.4))\n",
    "\n",
    "selected_days = [[2000,2500], [6500,7000], [11000,11500]]\n",
    "for d in selected_days:\n",
    "    plt.plot(d, [-1.3]*2, lw=2, color=\"k\")\n",
    "\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig5b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cinQZWurhJTJ"
   },
   "source": [
    "## Fig 5c-e\n",
    "\n",
    "_2.5 hours_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqGDm_-CBs-M"
   },
   "outputs": [],
   "source": [
    "outData = getRat(\"W080\")\n",
    "new_dat = psy.trim(outData, END=12500)\n",
    "\n",
    "FOLDS = 10  # number of cross-validation folds\n",
    "SEED = 42   # controls random divide of trials into FOLDS bins\n",
    "\n",
    "weights = {'bias': 1, 's_a': 1, 's_b': 1, 'h': 1, 'c': 1, \"s_avg\": 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**-4]*K,\n",
    "  }\n",
    "optList = ['sigma', 'sigDay']\n",
    "\n",
    "_, xval_pL = psy.crossValidate(new_dat, hyper_guess, weights, optList, F=FOLDS, seed=SEED)\n",
    "np.savez_compressed(SPATH+'fig5c_data.npz', new_dat=new_dat, xval_pL=xval_pL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTYeCHpWjKOm"
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "from scipy.stats import sem\n",
    "\n",
    "outData = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['new_dat'].item()\n",
    "xval_pL = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['xval_pL'] \n",
    "outData['xval_pR'] = 1 - xval_pL\n",
    "\n",
    "all_hists = []\n",
    "all_ys = []\n",
    "all_pRs = []\n",
    "\n",
    "selected_days = [[2000,2500], [6500,7000], [11000,11500]]\n",
    "for d in selected_days:\n",
    "    new_dat = psy.trim(outData, START=d[0], END=d[1])\n",
    "\n",
    "    hists = []\n",
    "    ys = []\n",
    "    pRs = []\n",
    "    for h in [-1,1]:\n",
    "        for c in [-1,1]:\n",
    "            for a in [-1,1]:\n",
    "                ind_h = (new_dat['inputs']['h'][:,0] == h)\n",
    "                ind_c = (new_dat['inputs']['c'][:,0] == c)\n",
    "                ind_a = (np.sign(new_dat['s_a'] - new_dat['s_b']) == a)\n",
    "                inds = ind_h * ind_c * ind_a\n",
    "                hists += [[h,c,a]]\n",
    "                ys += [new_dat['y'][inds]]\n",
    "                pRs += [new_dat['xval_pR'][inds]]\n",
    "    \n",
    "    all_hists += [hists]\n",
    "    all_ys += [ys]\n",
    "    all_pRs += [pRs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qct4U82ICo9j"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "def colorFader(c1,c2,mix=0):\n",
    "    c1=np.array(mpl.colors.to_rgb(c1))\n",
    "    c2=np.array(mpl.colors.to_rgb(c2))\n",
    "    w =np.array(mpl.colors.to_rgb(\"white\"))\n",
    "    if mix <= 0.5:\n",
    "        return mpl.colors.to_hex((1-mix*2)*c1 + mix*2*w)\n",
    "    else:\n",
    "        return mpl.colors.to_hex((1-(mix-0.5)*2)*w + (mix-0.5)*2*c2)\n",
    "\n",
    "def cF(mix):\n",
    "    return colorFader(colors['s2'],colors['s1'],mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P2brksHUZggm"
   },
   "outputs": [],
   "source": [
    "diff = 0.19\n",
    "rad = 0.45 \n",
    "cm = plt.get_cmap('RdBu_r')\n",
    "\n",
    "for d in range(len(selected_days)):\n",
    "    plt.figure(figsize=(0.75,1.5))\n",
    "    avg = [np.average(i) for i in all_ys[d]]\n",
    "    avg_pR = [np.average(i) for i in all_pRs[d]]\n",
    "\n",
    "    std = [sem(i) for i in all_ys[d]]\n",
    "    std_pR = [sem(i) for i in all_pRs[d]]\n",
    "\n",
    "    for i in range(len(avg)):\n",
    "        h = all_hists[d][i][0]\n",
    "        c = all_hists[d][i][1]\n",
    "        a = all_hists[d][i][2]\n",
    "        x = a/2\n",
    "        y = h + c/2\n",
    "\n",
    "        plt.text(x-diff, y+diff, int(np.round(avg_pR[i]*100)),\n",
    "                 ha=\"center\", va=\"center\", fontsize=10, zorder=i+1)\n",
    "        t1 = plt.Polygon([[x-rad,y-rad],[x-rad,y+rad],[x+rad,y+rad]], \n",
    "                         facecolor=cF(avg_pR[i]), edgecolor=\"k\", lw=0, zorder=i)\n",
    "        plt.gca().add_patch(t1)\n",
    "\n",
    "        plt.text(x+diff, y-1.5*diff, int(np.round(avg[i]*100)),\n",
    "                 ha=\"center\", va=\"center\", fontsize=10, zorder = i+11)\n",
    "        t2 = plt.Polygon([[x-rad,y-rad],[x+rad,y-rad],[x+rad,y+rad]], \n",
    "                         facecolor=cF(avg[i]), edgecolor=\"k\", lw=0.5, zorder = i+10)\n",
    "        plt.gca().add_patch(t2)\n",
    "        \n",
    "    plt.ylim(-2,2)\n",
    "    plt.xlim(-1,1)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_visible(False)\n",
    "    plt.gca().spines['bottom'].set_visible(False)\n",
    "    plt.gca().set_xticks([])\n",
    "    plt.gca().set_yticks([])\n",
    "\n",
    "    plt.subplots_adjust(0,0,1,1) \n",
    "    plt.savefig(SPATH + \"Fig5cde_\" + str(d) + \".pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pG50zZtbMaW1"
   },
   "outputs": [],
   "source": [
    "# Make colorbar\n",
    "n=500\n",
    "fig, ax = plt.subplots(figsize=(.2, 1.5))\n",
    "for x in range(n+1):\n",
    "    ax.axhline(1 - x/n, color=cF(x/n), linewidth=4) \n",
    "\n",
    "plt.gca().set_yticks([0.005,.25,.5,.75,0.995])\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig5_colorbar.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dvHbOKpcgfel"
   },
   "source": [
    "# Figure 6 | Population Psychometric Weights from Akrami Rats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lO9HJIvCgfel"
   },
   "source": [
    "**(A)** Show overlay of population weights (including the average weights) for Tones A + B\n",
    "\n",
    "**(B)** For the Bias weight\n",
    "\n",
    "**(C)** For the Previous Tones weight\n",
    "\n",
    "**(D)** For the Previous (Correct) Answer weight\n",
    "\n",
    "**(E)** For the Previous Choice weight\n",
    "\n",
    "**F)** Show average hyperparamter recovery ($\\sigma$ and $\\sigma_\\text{day}$) for each weight ($\\pm1$SD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-n6NsStgfem"
   },
   "source": [
    "## Figure 6a\n",
    "\n",
    "_6 hours_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T11:44:15.987858Z",
     "start_time": "2020-04-18T06:05:41.439554Z"
    },
    "id": "4stfPHurgfem"
   },
   "outputs": [],
   "source": [
    "all_rats = RAT_DF[\"subject_id\"].unique()\n",
    "for i, subject in enumerate(all_rats):\n",
    "\n",
    "    print(\"\\rProcessing \" + str(i+1) + \" of \" + str(len(all_rats)), end=\"\")\n",
    "        \n",
    "    outData = getRat(subject)\n",
    "\n",
    "    # Collect data from manually determined training period\n",
    "    new_dat = psy.trim(outData, END=20000)\n",
    "\n",
    "    # Compute\n",
    "    weights = {'bias': 1, 's_a': 1, 's_b': 1, 'h': 1, 'c': 1, \"s_avg\": 1}\n",
    "    K = np.sum([weights[i] for i in weights.keys()])\n",
    "    hyper_guess = {\n",
    "     'sigma'   : [2**-5]*K,\n",
    "     'sigInit' : 2**5,\n",
    "     'sigDay'  : [2**-4]*K,\n",
    "      }\n",
    "    optList = ['sigma', 'sigDay']\n",
    "\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList, hess_calc=None)\n",
    "\n",
    "    dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'hess_info' : hess_info,\n",
    "           'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "    # Save interim result\n",
    "    np.savez_compressed(SPATH+'fig6a_'+subject+'_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T11:44:17.751283Z",
     "start_time": "2020-04-18T11:44:15.990400Z"
    },
    "id": "AT1zPOzYgfeo"
   },
   "outputs": [],
   "source": [
    "all_labels = []\n",
    "all_w = []\n",
    "for subject in RAT_DF[\"subject_id\"].unique():\n",
    "    rat = np.load(SPATH+'fig6a_'+subject+'_data.npz', allow_pickle=True)['dat'].item()\n",
    "    \n",
    "    labels = []\n",
    "    for j in sorted(rat['weights'].keys()):\n",
    "        labels += [j]*rat['weights'][j]\n",
    "        \n",
    "    all_labels += [np.array(labels)]\n",
    "    all_w += [rat['wMode']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T11:44:17.818016Z",
     "start_time": "2020-04-18T11:44:17.754525Z"
    },
    "id": "hSRx7yIKgfeq"
   },
   "outputs": [],
   "source": [
    "def plot_all(all_labels, all_w, Weights, figsize):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    Weights = [Weights] if type(Weights) is str else Weights\n",
    "    avg_len=20000\n",
    "    for i, W in enumerate(Weights):\n",
    "        avg = []\n",
    "        for i in np.arange(0,len(all_w),1):\n",
    "            bias_ind = np.where(all_labels[i] == W)[0][-1]\n",
    "            bias_w = all_w[i][bias_ind]\n",
    "            avg += [list(bias_w[:avg_len]) + [np.nan]*(avg_len - len(bias_w[:avg_len]))]\n",
    "            plt.plot(bias_w, color=colors[W], alpha=0.2, lw=1, zorder=2+i)\n",
    "        plt.plot(np.nanmean(avg, axis=0), color=colors[W], alpha=0.8, lw=2.5, zorder=5+i)\n",
    "\n",
    "    plt.axhline(0, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=1)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.xlim(0, 19000)\n",
    "    plt.ylim(-2.5, 2.5)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:15:19.109985Z",
     "start_time": "2020-04-18T21:15:17.723564Z"
    },
    "id": "-9GHjPakgfer"
   },
   "outputs": [],
   "source": [
    "plot_all(all_labels, all_w, [\"s_a\", \"s_b\"], (1.85, 0.8))\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.gca().set_yticks([-2,0,2])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.savefig(SPATH + \"Fig6a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuQzsIVhgfet"
   },
   "source": [
    "## Figure 6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:15:23.320322Z",
     "start_time": "2020-04-18T21:15:22.295349Z"
    },
    "id": "M09bpTRmgfeu"
   },
   "outputs": [],
   "source": [
    "plot_all(all_labels, all_w, [\"bias\"], (1.85, 0.8))\n",
    "plt.gca().set_yticks([-2,0,2])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig6b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z0P3yj-Ogfex"
   },
   "source": [
    "## Figure 6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:15:25.248590Z",
     "start_time": "2020-04-18T21:15:24.408445Z"
    },
    "id": "bZuiZdkwgfey"
   },
   "outputs": [],
   "source": [
    "plot_all(all_labels, all_w, [\"s_avg\"], (1.85, 0.8))\n",
    "plt.gca().set_yticks([-2,0,2])\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig6c.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckITmRUCgfe0"
   },
   "source": [
    "## Figure 6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:15:27.542700Z",
     "start_time": "2020-04-18T21:15:26.671576Z"
    },
    "id": "OxbHunnBgfe0"
   },
   "outputs": [],
   "source": [
    "plot_all(all_labels, all_w, [\"h\"], (1.85, 0.8))\n",
    "plt.ylim(-0.25, 2.25)\n",
    "# plt.gca().set_yticklabels([])\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig6d.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afV-IoNYgfe2"
   },
   "source": [
    "## Figure 6e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:15:30.063634Z",
     "start_time": "2020-04-18T21:15:29.191788Z"
    },
    "id": "Y9hPucsRgfe2"
   },
   "outputs": [],
   "source": [
    "plot_all(all_labels, all_w, [\"c\"], (1.85, 0.8))\n",
    "plt.ylim(-0.25, 2.25)\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig6e.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCDHK1mpMpkf"
   },
   "source": [
    "## Figure 6f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q3zgxqJZMpxr"
   },
   "outputs": [],
   "source": [
    "all_sigma = []\n",
    "all_sigDay = []\n",
    "for subject in RAT_DF[\"subject_id\"].unique():\n",
    "    rat = np.load(SPATH+'fig6a_'+subject+'_data.npz', allow_pickle=True)['dat'].item()\n",
    "    \n",
    "    labels = []\n",
    "    for j in sorted(rat['weights'].keys()):\n",
    "        labels += [j]*rat['weights'][j]\n",
    "        \n",
    "    all_sigma += [rat['hyp']['sigma']]\n",
    "    all_sigDay += [rat['hyp']['sigDay']]\n",
    "\n",
    "all_sigma = np.array(all_sigma)\n",
    "all_sigDay = np.array(all_sigDay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3pc77-_Wtzr"
   },
   "outputs": [],
   "source": [
    "pos_map = {0: 2, 1: 5, 2: 4, 3: 0, 4: 3, 5: 1}\n",
    "plt.figure(figsize=(1.55, 0.8))\n",
    "for i, j in enumerate(labels):\n",
    "    plt.errorbar([pos_map[i]], np.average(np.log2(all_sigma[:,i])),\n",
    "                 yerr=np.std(np.log2(all_sigma[:,i])),\n",
    "                 color=colors[j], marker=\"o\", ms=4, elinewidth=1.5)\n",
    "    plt.errorbar([pos_map[i]+8], np.average(np.log2(all_sigDay[:,i])),\n",
    "                 yerr=np.std(np.log2(all_sigDay[:,i])),\n",
    "                 color=colors[j], marker=\"s\", ms=4, elinewidth=1.5)\n",
    "    \n",
    "plt.ylim(-12.5,-2.6)\n",
    "# plt.xlim(-1,1)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().set_xticks([])\n",
    "plt.gca().set_yticks([-12, -10, -8, -6, -4])\n",
    "plt.gca().set_yticklabels([-12, None, -8, None, -4])\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig6f.pdf\", transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPnv6hCJgfe4"
   },
   "source": [
    "# Figure 7 | Population Psychometric Weights from Akrami Human Subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujrm8sVVgfe4"
   },
   "source": [
    "**(A)** Athena human subject task schematic (Illustrator only)\n",
    "\n",
    "**(B)** Psychometric weights for an example human subject (`subject_id=6`)\n",
    "\n",
    "**(C)** Show psychometric weights for all human subjects together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSXeM2Zqgfe7"
   },
   "source": [
    "## Figure 7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T05:30:57.233280Z",
     "start_time": "2020-04-18T05:30:42.020789Z"
    },
    "id": "phSPrpF6gfe7"
   },
   "outputs": [],
   "source": [
    "new_dat = getHuman(6)\n",
    "\n",
    "# Compute\n",
    "weights = {'bias': 1, 's_a': 1, 's_b': 1, 's_avg': 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : None\n",
    "  }\n",
    "optList = ['sigma']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig7b_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T05:30:57.812127Z",
     "start_time": "2020-04-18T05:30:57.235931Z"
    },
    "id": "kJeQ94q-gfe9"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'fig7b_data.npz', allow_pickle=True)['dat'].item()\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], errorbar=dat['W_std'], figsize=(4.75,1))\n",
    "\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.gca().set_xticks([0,500,1000,1500,2000])\n",
    "plt.gca().set_yticks(np.arange(-2, 3,2))\n",
    "plt.xlim(0, 1900); plt.ylim(-3.4, 3.4)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig7b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzYo_DEZgfe_"
   },
   "source": [
    "## Figure 7c\n",
    "\n",
    "_3 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T05:34:09.463811Z",
     "start_time": "2020-04-18T05:32:00.008980Z"
    },
    "id": "CgdUOaK3gfe_"
   },
   "outputs": [],
   "source": [
    "all_dat = []\n",
    "all_subjects = HUMAN_DF[\"subject_id\"].unique()\n",
    "for i, subject in enumerate(all_subjects):\n",
    "    \n",
    "    print(\"\\rProcessing \" + str(i+1) + \" of \" + str(len(all_subjects)), end=\"\")\n",
    "\n",
    "    new_dat = getHuman(subject)\n",
    "\n",
    "    # Compute\n",
    "    weights = {'bias': 1, 's_a': 1, 's_b': 1, 's_avg': 1}\n",
    "    K = np.sum([weights[i] for i in weights.keys()])\n",
    "    hyper_guess = {\n",
    "     'sigma'   : [2**-5]*K,\n",
    "     'sigInit' : 2**5,\n",
    "     'sigDay'  : None\n",
    "      }\n",
    "    optList = ['sigma']\n",
    "\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "    dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "           'weights' : weights, 'new_dat' : new_dat}\n",
    "    all_dat += [dat]\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'fig7c_data.npz', all_dat=all_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T05:34:10.219953Z",
     "start_time": "2020-04-18T05:34:09.466468Z"
    },
    "id": "qgpW3PaHgffB"
   },
   "outputs": [],
   "source": [
    "all_dat = np.load(SPATH+'fig7c_data.npz', allow_pickle=True)['all_dat']\n",
    "\n",
    "plt.figure(figsize=(4.75,1))\n",
    "for dat in all_dat:\n",
    "\n",
    "    weights = dat['weights']\n",
    "    wMode = dat['wMode']\n",
    "    labels = []\n",
    "    for j in sorted(weights.keys()):\n",
    "        labels += [j]*weights[j]\n",
    "\n",
    "    for i, w in enumerate(labels):\n",
    "        plt.plot(wMode[i], lw=1.5, alpha=0.5, linestyle='-', c=colors[w], zorder=zorder[w])\n",
    "\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
    "plt.gca().set_xticks([0,500,1000,1500,2000])\n",
    "plt.gca().set_yticks(np.arange(-2, 3,2))\n",
    "plt.xlim(0, 1900); plt.ylim(-3.4, 3.4)\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig7c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4DwBkzYgffD"
   },
   "source": [
    "# Figure 8 | History Regressors Improve Model Accuracy for an Example Akrami Rat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awnKSjUvgffE"
   },
   "source": [
    "**(A)** Show plot for model w/o using history weights: predicted accuracy on x-axis, and empirical accuracy on y-axis\n",
    "\n",
    "**(B)** Show histogram of predicted accuracy in trials from (A)\n",
    "\n",
    "**(C)** Show plot for model with history weights: predicted accuracy on x-axis, and empirical accuracy on y-axis\n",
    "\n",
    "**(D)** Show histogram of predicted accuracy in trials from (C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbXd5x2JgffF"
   },
   "source": [
    "## Figure 8a\n",
    "\n",
    "_30 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T06:04:33.522786Z",
     "start_time": "2020-04-18T05:36:15.512179Z"
    },
    "id": "4wlqXPrxgffF"
   },
   "outputs": [],
   "source": [
    "outData = getRat(\"W080\")\n",
    "new_dat = psy.trim(outData, END=12500)\n",
    "\n",
    "FOLDS = 10  # number of cross-validation folds\n",
    "SEED = 42   # controls random divide of trials into FOLDS bins\n",
    "\n",
    "weights = {'bias': 1, 's_a': 1, 's_b': 1, 'h': 0, 'c': 0, \"s_avg\": 0}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**-4]*K,\n",
    "  }\n",
    "optList = ['sigma', 'sigDay']\n",
    "\n",
    "_, xval_pL = psy.crossValidate(new_dat, hyper_guess, weights, optList, F=FOLDS, seed=SEED)\n",
    "np.savez_compressed(SPATH+'fig8a_data.npz', new_dat=new_dat, xval_pL=xval_pL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T06:04:34.220336Z",
     "start_time": "2020-04-18T06:04:33.526202Z"
    },
    "id": "H0OK6ZJjgffH"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "xval_pL = np.load(SPATH+'../fig8a_data.npz', allow_pickle=True)['xval_pL'] \n",
    "new_dat = np.load(SPATH+'../fig8a_data.npz', allow_pickle=True)['new_dat'].item()\n",
    "\n",
    "step = 0.02\n",
    "edges = np.arange(0.5,1.0+step,step)\n",
    "\n",
    "est_correct = np.abs(xval_pL - 0.5) + 0.5\n",
    "match = ((-np.sign(xval_pL - 0.5) + 1)/2).astype(int) == new_dat[\"y\"].astype(int)\n",
    "\n",
    "print(\"Average Empirical Accuracy:\", np.round(np.average(match), 3))\n",
    "print(\"Average Predicted Accuracy:\", np.round(np.average(est_correct), 3))\n",
    "\n",
    "choices = []\n",
    "centers = []\n",
    "for i in edges[:-1]:\n",
    "    mask = (est_correct >= i) & (est_correct < i+step)\n",
    "    choices += [match[mask]]\n",
    "    centers += [np.average(est_correct[mask])];\n",
    "\n",
    "avg_correct = np.array([np.average(i) if len(i) > 40 else np.nan for i in choices])\n",
    "sem_correct = np.array([sem(i) if len(i) > 40 else np.nan for i in choices])\n",
    "\n",
    "plt.figure(figsize=(2,1.5))\n",
    "plt.errorbar(centers, avg_correct, yerr=1.96*sem_correct,\n",
    "             alpha=1, color=colors['bias'], linestyle=\"None\", marker=\"o\", markersize=2)\n",
    "plt.plot(np.average(est_correct), np.average(match), marker=\"*\", markersize=10, alpha=0.75,\n",
    "         markeredgecolor=\"None\", markerfacecolor=\"black\", zorder=10)\n",
    "\n",
    "plt.plot([0.4,1.1], [0.4,1.1], color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
    "\n",
    "plt.xlim(0.5, 1)\n",
    "plt.ylim(0.5, 1)\n",
    "plt.xticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "plt.gca().set_xticklabels([])\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig8a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MD64fWrYgffK"
   },
   "source": [
    "## Figure 8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T06:04:34.883172Z",
     "start_time": "2020-04-18T06:04:34.223286Z"
    },
    "id": "0eVXehmGgffL"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,1.5))\n",
    "plt.hist(est_correct, bins=edges, alpha=1, lw=0.5, color=colors['bias'], edgecolor=\"black\")\n",
    "\n",
    "plt.xlim(0.5, 1)\n",
    "plt.ylim(0, 1700)\n",
    "plt.xticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig8b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rAeRQbfPgffN"
   },
   "source": [
    "## Figure 8c\n",
    "\n",
    "These subfigures reuse data from Figure 5C-E, please go run the cell above that creates the file `fig5c_data.npz` to produce Figures 8C+D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T05:35:36.113332Z",
     "start_time": "2020-04-18T05:35:35.821578Z"
    },
    "id": "QDqqPJ6TgffO"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import sem\n",
    "xval_pL = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['xval_pL'] \n",
    "new_dat = np.load(SPATH+'fig5c_data.npz', allow_pickle=True)['new_dat'].item()\n",
    "\n",
    "step = 0.02\n",
    "edges = np.arange(0.5,1.0+step,step)\n",
    "\n",
    "est_correct = np.abs(xval_pL - 0.5) + 0.5\n",
    "match = ((-np.sign(xval_pL - 0.5) + 1)/2).astype(int) == new_dat[\"y\"].astype(int)\n",
    "\n",
    "print(\"Average Empirical Accuracy:\", np.round(np.average(match), 3))\n",
    "print(\"Average Predicted Accuracy:\", np.round(np.average(est_correct), 3))\n",
    "\n",
    "choices = []\n",
    "centers = []\n",
    "for i in edges[:-1]:\n",
    "    mask = (est_correct >= i) & (est_correct < i+step)\n",
    "    choices += [match[mask]]\n",
    "    centers += [np.average(est_correct[mask])];\n",
    "\n",
    "avg_correct = np.array([np.average(i) if len(i) > 40 else np.nan for i in choices])\n",
    "sem_correct = np.array([sem(i) if len(i) > 40 else np.nan for i in choices])\n",
    "\n",
    "plt.figure(figsize=(2,1.5))\n",
    "plt.errorbar(centers, avg_correct, yerr=1.96*sem_correct,\n",
    "             alpha=1, color=colors['h'], linestyle=\"None\", marker=\"o\", markersize=2)\n",
    "plt.plot(np.average(est_correct), np.average(match), marker=\"*\", markersize=10, alpha=0.75,\n",
    "         markeredgecolor=\"None\", markerfacecolor=\"black\", zorder=10)\n",
    "\n",
    "plt.plot([0.4,1.1], [0.4,1.1], color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
    "\n",
    "plt.xlim(0.5, 1)\n",
    "plt.ylim(0.5, 1)\n",
    "plt.xticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.gca().set_yticklabels([])\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig8c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sf0al5ewgffQ"
   },
   "source": [
    "## Figure 8d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T05:35:42.443362Z",
     "start_time": "2020-04-18T05:35:41.840784Z"
    },
    "id": "duOzrCfWgffQ"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2,1.5))\n",
    "plt.hist(est_correct, bins=edges, alpha=1, lw=0.5, color=colors['h'], edgecolor=\"black\")\n",
    "\n",
    "plt.xlim(0.5, 1)\n",
    "plt.ylim(0, 1700)\n",
    "plt.xticks([0.5,0.6,0.7,0.8,0.9,1.0])\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"Fig8d.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vseelEMob2nS"
   },
   "source": [
    "#     \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AjpYNikwgffV"
   },
   "source": [
    "# Supplementary Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASvO-FZdT978"
   },
   "source": [
    "## Figure S1 | Compute time and model accuracy\n",
    "\n",
    "**(A)** Show compute time\n",
    "\n",
    "**(B)** Show weight recovery accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8wYF2mYgffW"
   },
   "source": [
    "### Figure S1a\n",
    "\n",
    "_5 hours_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T11:44:17.907716Z",
     "start_time": "2020-04-18T07:45:23.591Z"
    },
    "id": "tFeRSZ7ZgffW"
   },
   "outputs": [],
   "source": [
    "from psytrack.runSim import generateSim, recoverSim\n",
    "\n",
    "num_weights = [2,4,6]\n",
    "num_trials = 1000*np.array([1,2,4,8,16])\n",
    "num_simulations = 20\n",
    "\n",
    "results = []\n",
    "\n",
    "for N in num_trials:\n",
    "    for K in num_weights:\n",
    "        for i in range(num_simulations):\n",
    "            print(\"K =\", K, \"  N =\", N, \"  iter = \", i)\n",
    "            # Simulate data\n",
    "            seed = N+100*K+i\n",
    "            np.random.seed(seed)\n",
    "            hyper = {'sigma': 2**np.random.uniform(-7.5, -3.5, size=K), 'sigInit': 1.0}\n",
    "            dat = generateSim(K=K, N=N, hyper=hyper, boundary=5.0, iterations=1, seed=seed)\n",
    "            \n",
    "            # Recover data\n",
    "            try:\n",
    "                rec = recoverSim(dat, hess_calc=None)\n",
    "            except:\n",
    "                print(\"ERROR!!!\")\n",
    "                results += [[N, K, i, np.nan, np.nan]]\n",
    "                continue\n",
    "            \n",
    "            # Save all data, mainly duration and mean squared error in weight recovery\n",
    "            mse = np.average((rec['wMode'] - rec['input']['W'].T)**2)\n",
    "            print(\"      \" + str(rec['duration'].seconds) +\"s   mse =\", np.round(mse, 4))\n",
    "            results += [[N, K, i, rec['duration'], mse]]\n",
    "            \n",
    "# Update saved record of all info on each iteration\n",
    "np.savez(SPATH + \"FigS1_dat.npz\", results=results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntObgps1gffY"
   },
   "outputs": [],
   "source": [
    "res = np.load(SPATH + \"FigS1_dat.npz\", allow_pickle=True)['results']\n",
    "\n",
    "plt.figure(figsize=(2.5,2.5))\n",
    "COLORS = [colors['bias'],colors['s1'],colors['s2'],]\n",
    "adjust = [-0.3, 0, 0.3]\n",
    "for i, K in enumerate(num_weights):\n",
    "    all_duration = [i[3] for i in res if i[1]==K]\n",
    "    all_duration = np.array([i.total_seconds()/60\n",
    "                             if i is not None else np.nan\n",
    "                             for i in all_duration]).reshape(-1,num_simulations)\n",
    "    plt.errorbar(num_trials/1000 + adjust[i], np.nanmean(all_duration, axis=1),\n",
    "                 yerr=np.nanstd(all_duration, axis=1),\n",
    "                 color=COLORS[i], marker=\"o\", markersize=3, lw=1)\n",
    "\n",
    "\n",
    "plt.xlim(0.25, 16.5)\n",
    "plt.ylim(0, 8.2)\n",
    "plt.xticks([1,2,4,8,16])\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS1a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T16:16:42.028103Z",
     "start_time": "2020-04-07T16:16:41.976184Z"
    },
    "id": "T-GAuSxKgffZ"
   },
   "source": [
    "### Figure S1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70IYar3jgffa"
   },
   "outputs": [],
   "source": [
    "res = np.load(SPATH + \"FigS1_dat.npz\", allow_pickle=True)['results']\n",
    "\n",
    "plt.figure(figsize=(2.5,2.5))\n",
    "COLORS = [colors['bias'],colors['s1'],colors['s2']]\n",
    "adjust = [-0.3, 0, 0.3]\n",
    "for i, K in enumerate(num_weights):\n",
    "    all_mse = [i[4] for i in res if i[1]==K]\n",
    "    all_mse = np.array([i if i is not None else np.nan\n",
    "                        for i in all_mse]).reshape(-1,num_simulations)\n",
    "    plt.errorbar(num_trials/1000 + adjust[i], np.nanmean(all_mse, axis=1),\n",
    "                 yerr=np.nanstd(all_mse, axis=1),\n",
    "                 color=COLORS[i], linestyle=\"None\", marker=\"o\", markersize=3, lw=1)\n",
    "\n",
    "plt.xlim(0.25, 16.5); plt.ylim(0, 0.152)\n",
    "plt.xticks([1,2,4,8,16]); plt.yticks([0,0.05,0.1,0.15])\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS1b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY9jHl8tULNy"
   },
   "source": [
    "## Figure S2 | Recovering sudden changes in behavior with smooth weight trajectories\n",
    "\n",
    "**(A)** Same as (2C) but without including $\\sigma_\\text{day}$ in the recovery model\n",
    "\n",
    "**(B)** Same as (2D) but without including $\\sigma_\\text{day}$ in the recovery model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MkFcHmP4boke"
   },
   "source": [
    "### Figure S2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:22:30.507549Z",
     "start_time": "2020-04-18T01:22:30.451982Z"
    },
    "id": "9hiM4nher1Ge"
   },
   "outputs": [],
   "source": [
    "# Simulate\n",
    "seed = 102  # paper uses 102\n",
    "num_weights = 3\n",
    "num_trials = 5000\n",
    "hyper = {'sigma'   : 2**np.array([-4.5, -5.0,-16.0]),\n",
    "         'sigInit' : 2**np.array([ 0.0,  0.0,  0.0]),\n",
    "         'sigDay'  : 2**np.array([ 0.5,-16.0,  1.0])\n",
    "        }\n",
    "days = [500]*9\n",
    "\n",
    "# Compute\n",
    "gen = psy.generateSim(K=num_weights, N=num_trials, hyper=hyper, days=days,\n",
    "                      boundary=10.0, iterations=1, seed=seed, savePath=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:24:04.446435Z",
     "start_time": "2020-04-18T01:22:31.149855Z"
    },
    "id": "s1WzrA11r1Gj"
   },
   "outputs": [],
   "source": [
    "# Recovery\n",
    "gen['dayLength'] = None\n",
    "rec = psy.recoverSim(gen)\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS2_data.npz', rec=rec, gen=gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:24:05.242522Z",
     "start_time": "2020-04-18T01:24:04.449465Z"
    },
    "id": "KVxzrVZ4r1Gn"
   },
   "outputs": [],
   "source": [
    "# Reload data\n",
    "rec = np.load(SPATH+'figS2_data.npz', allow_pickle=True)['rec'].item()\n",
    "gen = np.load(SPATH+'figS2_data.npz', allow_pickle=True)['gen'].item()\n",
    "\n",
    "# Plotting\n",
    "sim_colors = [colors['bias'], colors['s1'], colors['s2']]\n",
    "fig = plt.figure(figsize=(3.75,1.4))\n",
    "for i, c in enumerate(sim_colors):\n",
    "    plt.plot(gen['W'][:,i], c=c, lw=0.5, zorder=5-i)\n",
    "    plt.plot(rec['wMode'][i], c=c, lw=1, linestyle='--', alpha=0.5, zorder=5-i)\n",
    "    plt.fill_between(np.arange(num_trials),\n",
    "                     rec['wMode'][i] - 2 * rec['hess_info']['W_std'][i],\n",
    "                     rec['wMode'][i] + 2 * rec['hess_info']['W_std'][i],\n",
    "                     facecolor=c, alpha=0.2, zorder=5-i)\n",
    "\n",
    "for i in np.cumsum(days):\n",
    "    plt.axvline(i, color=\"black\", lw=0.5, alpha=0.5, zorder=0)\n",
    "    \n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=0.5, alpha=0.5, zorder=0)\n",
    "plt.xticks(1000*np.arange(0,6))\n",
    "plt.gca().set_xticklabels([0,1000,2000,3000,4000,5000])\n",
    "plt.yticks(np.arange(-4,5,2))\n",
    "\n",
    "plt.xlim(0,5000); plt.ylim(-4.3,4.3)\n",
    "# plt.xlabel(\"Trials\"); plt.ylabel(\"Weights\")\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS2a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOh5EqaQbs3G"
   },
   "source": [
    "### Figure S2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07MswdJEkhOR"
   },
   "outputs": [],
   "source": [
    "# Reload data\n",
    "rec = np.load(SPATH+'figS2_data.npz', allow_pickle=True)['rec'].item()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(1.4,1.4))\n",
    "\n",
    "true_sigma = np.log2(rec['input']['sigma'])\n",
    "avg_sigma = np.log2(rec['hyp']['sigma'])\n",
    "err_sigma = rec['hess_info']['hyp_std'][:3]\n",
    "for i, c in enumerate(sim_colors):\n",
    "    plt.plot([i-0.3, i+0.3], [true_sigma[i]]*2, color=\"black\", linestyle=\"-\", lw=1.2, zorder=0)\n",
    "    plt.errorbar([i], avg_sigma[i], yerr=1.96*err_sigma[i], c=c, lw=1, marker='o', markersize=5)\n",
    "\n",
    "plt.axvspan(1.6,2.4, facecolor=\"black\", edgecolor=\"none\", alpha=0.1)\n",
    "plt.xticks(np.arange(3))\n",
    "# plt.yticks([-8,-6,-4,-2,0,2])\n",
    "plt.gca().set_xticklabels([r\"$\\sigma_1$\",\n",
    "                           r\"$\\sigma_2$\", \n",
    "                           r\"$\\sigma_3$\"])\n",
    "plt.xlim(-0.5,2.5); plt.ylim(-7.5,-2.5)\n",
    "# plt.ylabel(r\"$\\log_2(\\sigma)$\")\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS2b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHCHvT08WCsI"
   },
   "source": [
    "## Figure S3 | Adding weights to early training sessions in IBL mice\n",
    "\n",
    "**(A)** Refit model from Figure 3b, with history regressor weights\n",
    "\n",
    "**(B)** Refit model from Figure 3b, with bias weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FnYu3m2jgffc"
   },
   "source": [
    "### Figure S3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:16:58.137158Z",
     "start_time": "2020-04-18T21:15:53.554577Z"
    },
    "id": "ZBl6Y6DRgffc"
   },
   "outputs": [],
   "source": [
    "# Collect data from manually determined training period\n",
    "outData = getMouse('CSHL_003', 5)\n",
    "\n",
    "prev_choice = np.hstack(([0], outData['y'][:-1]*2 - 3)).reshape(-1,1)\n",
    "prev_answer = np.hstack(([0], outData['answer'][:-1]*2 - 3)).reshape(-1,1)\n",
    "outData['inputs']['c'] = prev_choice\n",
    "outData['inputs']['h'] = prev_answer\n",
    "\n",
    "new_dat = psy.trim(outData, END=7000)\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 0, 'cL' : 1, 'cR' : 1, 'h' : 1, 'c' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : None\n",
    "  }\n",
    "optList = ['sigma']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS3a_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:16:58.992824Z",
     "start_time": "2020-04-18T21:16:58.139960Z"
    },
    "id": "PxDgBeCJgffe"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'figS3a_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
    "\n",
    "plt.axvline(np.cumsum(dat['new_dat']['dayLength'])[8], c=\"black\", lw=1.5, ls=\"--\", zorder=15)\n",
    "plt.ylim(-5.3,5.3)\n",
    "plt.xlim(0, 6950)\n",
    "plt.yticks([-4,-2,0,2,4])\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS3a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XiDbAJF_gfff"
   },
   "source": [
    "### Figure S3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:18:02.691538Z",
     "start_time": "2020-04-18T21:16:58.995712Z"
    },
    "id": "wu-_q82Zgffg"
   },
   "outputs": [],
   "source": [
    "# Collect data from manually determined training period\n",
    "outData = getMouse('CSHL_003', 5)\n",
    "\n",
    "new_dat = psy.trim(outData, END=7000)\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : None\n",
    "  }\n",
    "optList = ['sigma']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS3b_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:18:03.502254Z",
     "start_time": "2020-04-18T21:18:02.693872Z"
    },
    "id": "Ke-_V1aTgffh"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'figS3b_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
    "\n",
    "plt.axvline(np.cumsum(dat['new_dat']['dayLength'])[8], c=\"black\", lw=1.5, ls=\"--\", zorder=15)\n",
    "plt.ylim(-5.3,5.3)\n",
    "plt.xlim(0, 6950)\n",
    "plt.yticks([-4,-2,0,2,4])\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS3b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ewa2Gz8JWUWS"
   },
   "source": [
    "## Figure S4 | The impact of the $\\tanh$ transformation of IBL contrasts on model weights\n",
    "\n",
    "**(A)** $\\tanh$ tranformation on IBL contrasts\n",
    "\n",
    "**(B)** Refit model from Figure 3b, without $\\tanh$ transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GMs8J6nXgffj"
   },
   "source": [
    "### Figure S4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:18:46.285063Z",
     "start_time": "2020-04-18T21:18:45.500800Z"
    },
    "id": "4R4_pYK3gffk"
   },
   "outputs": [],
   "source": [
    "contrasts = [-1, -0.5, -0.25, -0.125, -0.0625, 0, 0.0625, 0.125, 0.25, 0.5, 1.0]\n",
    "def tanh_transform(c, p):\n",
    "    return np.tanh(p*np.array(c))/np.tanh(p)\n",
    "\n",
    "\n",
    "COLORS = [colors['s_avg'], colors['c'], colors['h']]\n",
    "plt.figure(figsize=(2.25, 2.25))\n",
    "plt.plot(contrasts, contrasts, \"ko-\", markersize=3, lw=1, label=\"Original\")\n",
    "for i, j in enumerate([1,3,5]):\n",
    "    plt.plot(contrasts, tanh_transform(contrasts, j),\n",
    "             \"o-\", markersize=3, lw=1, color=COLORS[i], label=r\"$p = $\" +str(j))\n",
    "\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=0.5, zorder=0)#, alpha=0.5)\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\", lw=0.5, zorder=0)#, alpha=0.5)\n",
    "plt.legend(fontsize=10)\n",
    "\n",
    "# plt.xlabel(\"Original Contrasts\"); plt.ylabel(\"Transformed Contrasts\")\n",
    "plt.xlim(-1.05,1.05); plt.ylim(-1.05,1.05)\n",
    "plt.xticks(contrasts, va=\"top\", ha=\"center\")\n",
    "plt.yticks(contrasts, rotation=90, va=\"center\", ha=\"right\", ma=\"center\")\n",
    "plt.gca().set_xticklabels([\"100%\\nLeft\",None,None,None,None,0,None,None,None,None,\"100%\\nRight\"])\n",
    "plt.gca().set_yticklabels([\"100%\\nLeft\",None,None,None,None,0,None,None,None,None,\"100%\\nRight\"])\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS4a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXDOmRvsgffl"
   },
   "source": [
    "### Figure S4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:20:14.311129Z",
     "start_time": "2020-04-18T21:18:48.752204Z"
    },
    "id": "E9yv_dgrgffm"
   },
   "outputs": [],
   "source": [
    "# Collect data from manually determined training period\n",
    "outData = getMouse(\"CSHL_003\", 0.00001)\n",
    "_start  = np.where(outData['date'] >= '2019-03-21')[0][0]\n",
    "_end    = np.where(outData['date'] >= '2019-03-23')[0][0]\n",
    "new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "# Hardcode random trials where probL != 0.5 before bias blocks begin to 0.5\n",
    "new_dat['probL'][:np.where(new_dat['date'] >= '2019-03-22')[0][0]] = 0.5\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**-5]*K\n",
    "  }\n",
    "optList = ['sigma', 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS4b_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:20:15.141426Z",
     "start_time": "2020-04-18T21:20:14.314075Z"
    },
    "id": "S35DlIJtgffo"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'figS4b_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(3,1.5))\n",
    "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
    "\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.gca().set_yticks(np.arange(-15,16,5))\n",
    "plt.ylim(-16.3,16.3)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS4b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ApcujXKpWf5i"
   },
   "source": [
    "## Figure S5 | Validating the model with a comparison to empirical psychometric curves\n",
    "\n",
    "**(A)** Using the mouse from (4), show the weights recovered from Session 10\n",
    "\n",
    "**(B)** As in (A), for Session 20 (now with a bias weight and bias blocks)\n",
    "\n",
    "**(C)** As in (A), for Session 40\n",
    "\n",
    "**(D)** Generate a psychometric curve from predictions derived from the model weights (in pink) and a curve caluclated from the empirical choice behavior (in black)\n",
    "\n",
    "**(E)** As in (D), for Session 20\n",
    "\n",
    "**(F)** As in (D), for Session 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3rQRP8oW8VL"
   },
   "source": [
    "### Figure S5a\n",
    "\n",
    "_(3 min)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjJwjKUh2sQW"
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "from scipy.stats import sem\n",
    "\n",
    "FOLDS = 10  # number of cross-validation folds\n",
    "SEED = 42   # controls random divide of trials into FOLDS bins\n",
    "\n",
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "outData['contrast'] = outData['contrastRight'] - outData['contrastLeft']\n",
    "\n",
    "all_cs = []\n",
    "all_ys = []\n",
    "all_pRs = []\n",
    "\n",
    "all_days = np.unique(outData['date'])\n",
    "selected_days = [10,20,40]\n",
    "for d in selected_days:\n",
    "    _start  = np.where(outData['date'] >= all_days[d])[0][0]\n",
    "    _end    = np.where(outData['date'] > all_days[d])[0][0] + 1\n",
    "    _end = _start + ((_end-_start)//FOLDS * FOLDS)\n",
    "    new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "    if d < 15:\n",
    "        weights = {'bias' : 0, 'cL' : 1, 'cR' : 1}\n",
    "    else:\n",
    "        weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "    K = np.sum([weights[i] for i in weights.keys()])\n",
    "    hyper_guess = {\n",
    "    'sigma'   : [2**-5]*K,\n",
    "    'sigInit' : 2**5,\n",
    "    'sigDay'  : None\n",
    "    }\n",
    "    optList = ['sigma']\n",
    "\n",
    "    _, _, wMode, hess_info = psy.hyperOpt(new_dat.copy(), hyper_guess, weights, optList)\n",
    "    _, xval_pL = psy.crossValidate(new_dat.copy(), hyper_guess, weights, optList,\n",
    "                                   F=FOLDS, seed=SEED)\n",
    "    pR = 1 - xval_pL\n",
    "\n",
    "    cs = []\n",
    "    ys = []\n",
    "    pRs = []\n",
    "    for c in np.unique(new_dat['contrast']):\n",
    "        cs += [c]\n",
    "        inds = (new_dat['contrast'] == c)\n",
    "        ys += [new_dat['y'][inds] - 1]\n",
    "        pRs += [pR[inds]]\n",
    "    all_cs += [cs]\n",
    "    all_ys += [ys]\n",
    "    all_pRs += [pRs]\n",
    "\n",
    "    # Plot weights\n",
    "    fig = psy.plot_weights(wMode, weights, days=None, \n",
    "                           errorbar=hess_info['W_std'], figsize=(1.75,1.5))\n",
    "\n",
    "    plt.xlabel(None); plt.ylabel(None)\n",
    "    plt.gca().set_yticks(np.arange(-4,6,2))\n",
    "    plt.ylim(-5.3,5.3)\n",
    "    if d > 15:\n",
    "        fig = addBiasBlocks(fig, new_dat['probL'])\n",
    "        plt.gca().set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(0,0,1,1) \n",
    "    plt.savefig(SPATH + \"FigS5abc_\" + str(d) + \".pdf\")\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS5_data.npz', \n",
    "                    all_cs=all_cs, all_ys=all_ys, all_pRs=all_pRs,\n",
    "                    selected_days=selected_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rm35GvPuXFOJ"
   },
   "source": [
    "### Figure S5d-f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rs30tz8z2sYL"
   },
   "outputs": [],
   "source": [
    "all_cs = np.load(SPATH+'figS5_data.npz', allow_pickle=True)['all_cs']\n",
    "all_ys = np.load(SPATH+'figS5_data.npz', allow_pickle=True)['all_ys']\n",
    "all_pRs = np.load(SPATH+'figS5_data.npz', allow_pickle=True)['all_pRs']\n",
    "selected_days = np.load(SPATH+'figS5_data.npz', allow_pickle=True)['selected_days']\n",
    "\n",
    "# Plotting\n",
    "diff = 0.01\n",
    "for d, ind in enumerate(selected_days):\n",
    "    plt.figure(figsize=(1.75,1.5))\n",
    "    avg = [np.average(i) for i in all_ys[d]]\n",
    "    std = [sem(i) for i in all_ys[d]]\n",
    "    plt.errorbar(np.array(all_cs[d])-diff, avg, yerr=std, color=\"black\", \n",
    "                 alpha=1.0, ls=\"-\", lw=0.4, marker='_', markersize=3, elinewidth=1.3)\n",
    "\n",
    "    avg_pR = [np.average(i) for i in all_pRs[d]]\n",
    "    std_pR = [sem(i) for i in all_ys[d]]\n",
    "    plt.errorbar(np.array(all_cs[d])+diff, avg_pR, yerr=std_pR, color=colors['emp_perf'],\n",
    "                 alpha=1.0, ls=\"none\", marker='_', markersize=3, elinewidth=1.3)\n",
    "    \n",
    "    plt.ylim(-0.01,1.01)\n",
    "    plt.xlim(-1-4*diff,1+4*diff)\n",
    "    plt.axvline(0, linestyle='--', color=\"black\", lw=0.5, alpha=0.5, zorder=1)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().set_yticks([0,0.5,1])\n",
    "    if not d:\n",
    "        plt.gca().set_yticklabels([0,None,1])\n",
    "    else:\n",
    "        plt.gca().set_yticklabels([])\n",
    "    plt.gca().set_xticks([-1,-0.5,-0.25,-.125,-.0625,0,0.0625,0.125,0.25,0.5,1])\n",
    "    plt.gca().set_xticklabels([])\n",
    "\n",
    "    # plt.title(d)\n",
    "    plt.subplots_adjust(0,0,1,1) \n",
    "    plt.savefig(SPATH + \"FigS5def_\" + str(d) + \".pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpPZFmuHWheq"
   },
   "source": [
    "## Figure S6 | Allowing the bias weight to reset between bias blocks with $\\sigma_\\text{day}$\n",
    "\n",
    "Replica of Figure 4, except bias block boundaries are treated as session boundaries and $\\sigma_\\text{day}$ is fixed to a large value, allowing for a \"reset\" of the bias weight between bias blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1VTzBDOta4_d"
   },
   "source": [
    "### Figure S6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:45:44.476264Z",
     "start_time": "2020-04-18T01:45:09.894803Z"
    },
    "id": "wRusj7trwudl"
   },
   "outputs": [],
   "source": [
    "# Collect data from manually determined training period\n",
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "_start  = np.where(outData['date'] >= '2019-03-21')[0][0]\n",
    "_end    = np.where(outData['date'] >= '2019-03-23')[0][0]\n",
    "new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "# Hardcode random trials where probL != 0.5 before bias blocks begin to 0.5\n",
    "# (fyi, this is due to anti-biasing in the IBL early training protocol)\n",
    "new_dat['probL'][:np.where(new_dat['date'] >= '2019-03-22')[0][0]] = 0.5\n",
    "probL_bound = np.where(new_dat['probL'][1:] - new_dat['probL'][:-1] != 0)[0] + 1\n",
    "old_dayLength = new_dat['dayLength']\n",
    "new_dat['dayLength'] = np.hstack((probL_bound[:1], np.diff(probL_bound)))\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**5, 2**-5., 2**-5.]\n",
    "  }\n",
    "optList = ['sigma']#, 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat, 'old_dayLength': old_dayLength}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS6b_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:45:44.535995Z",
     "start_time": "2020-04-18T01:45:44.478715Z"
    },
    "id": "Dszcb-h_wudq"
   },
   "outputs": [],
   "source": [
    "BIAS_COLORS = {50 : 'None', 20 : psy.COLORS['sR'], 80 : psy.COLORS['sL']}\n",
    "def addBiasBlocks(fig, pL):\n",
    "    plt.sca(fig.gca())\n",
    "    i = 0\n",
    "    while i < len(pL):\n",
    "        start = i\n",
    "        while i+1 < len(pL) and np.linalg.norm(pL[i] - pL[i+1]) < 0.0001:\n",
    "            i += 1\n",
    "        fc = BIAS_COLORS[int(100 * pL[start])]\n",
    "        plt.axvspan(start, i+1, facecolor=fc, alpha=0.2, edgecolor=None)\n",
    "        i += 1\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:45:45.273854Z",
     "start_time": "2020-04-18T01:45:44.540219Z"
    },
    "id": "ewocypBDwudv"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'figS6b_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat[\"old_dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
    "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
    "\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.gca().set_yticks(np.arange(-6, 7,2))\n",
    "plt.ylim(-5.3,5.3)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS6b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfM2vRhdwudx"
   },
   "source": [
    "### Figure S6c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:46:57.043289Z",
     "start_time": "2020-04-18T01:46:26.469282Z"
    },
    "id": "-dw28-WYwudy"
   },
   "outputs": [],
   "source": [
    "# Collect data from manually determined training period\n",
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "_start  = np.where(outData['date'] >= '2019-04-30')[0][0]\n",
    "_end    = np.where(outData['date'] >= '2019-05-02')[0][0]\n",
    "new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "# Compute\n",
    "probL_bound = np.where(new_dat['probL'][1:] - new_dat['probL'][:-1] != 0)[0] + 1\n",
    "old_dayLength = new_dat['dayLength']\n",
    "new_dat['dayLength'] = np.hstack((probL_bound[:1], np.diff(probL_bound)))\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**5, 2**-5., 2**-5.]\n",
    "  }\n",
    "optList = ['sigma']#, 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat, 'old_dayLength': old_dayLength}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS6c_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:46:57.738587Z",
     "start_time": "2020-04-18T01:46:57.045770Z"
    },
    "id": "hqx8IbwOwud0"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'figS6c_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat[\"old_dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
    "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
    "\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.gca().set_yticks(np.arange(-6, 7,2))\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.ylim(-5.3,5.3)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS6c.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEAS4Cfkwud2"
   },
   "source": [
    "### Figure S6d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:47:50.006569Z",
     "start_time": "2020-04-18T01:46:57.741749Z"
    },
    "id": "vuvKQsGJwud3"
   },
   "outputs": [],
   "source": [
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "\n",
    "# Collect data from manually determined training period\n",
    "_start  = np.where(outData['date'] >= '2019-03-22')[0][0]\n",
    "_end    = np.where(outData['date'] >= '2019-03-26')[0][0]\n",
    "new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "# Hardcode random trials where probL != 0.5 before bias begins to 0.5\n",
    "# (fyi, this is due to anti-biasing in the IBL early training protocol)\n",
    "new_dat['probL'][:np.where(new_dat['date'] >= '2019-03-22')[0][0]] = 0.5\n",
    "probL_bound = np.where(new_dat['probL'][1:] - new_dat['probL'][:-1] != 0)[0] + 1\n",
    "old_dayLength = new_dat['dayLength']\n",
    "new_dat['dayLength'] = np.hstack((probL_bound[:1], np.diff(probL_bound)))\n",
    "\n",
    "# Compute\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**5, 2**-5., 2**-5.]\n",
    "  }\n",
    "optList = ['sigma']#, 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat, 'old_dayLength': old_dayLength}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS6d_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:47:50.732024Z",
     "start_time": "2020-04-18T01:47:50.010315Z"
    },
    "id": "Q2YOvf2Iwud5"
   },
   "outputs": [],
   "source": [
    "def bias_diff(dat_load, figsize=(1.5,1.5)):\n",
    "    dat = np.load(dat_load, allow_pickle=True)['dat'].item()\n",
    "    pL = dat['new_dat']['probL']\n",
    "    pL_diff = pL[1:] - pL[:-1]\n",
    "    inds = np.where(pL_diff)[0]\n",
    "    start_inds = [0] + list(inds+1)\n",
    "    start_inds = [i for i in start_inds if (np.isclose(pL[i], 0.2) or np.isclose(pL[i], 0.8))]\n",
    "    end_inds = list(inds) + [len(pL)-1]\n",
    "    end_inds = [i for i in end_inds if (np.isclose(pL[i], 0.2) or np.isclose(pL[i], 0.8))]\n",
    "\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    for s, e in zip(start_inds, end_inds):\n",
    "        if e-s < 20: continue\n",
    "        block_inds = np.arange(s, e+1)\n",
    "        block = dat['wMode'][0, block_inds] - dat['wMode'][0, s]\n",
    "        if np.isclose(pL[s], 0.2):\n",
    "            plt.plot(block, color=colors['cR'], alpha=0.8, zorder=2, lw=1)\n",
    "        else:\n",
    "            plt.plot(block, color=colors['cL'], alpha=0.8, zorder=4, lw=1)\n",
    "    \n",
    "    plt.axhline(0, linestyle='--', color=\"black\", lw=1, alpha=0.5, zorder=0)\n",
    "    plt.ylim(-5.5,5.5)\n",
    "    plt.xlim(0, 75)\n",
    "\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.subplots_adjust(0,0,1,1)\n",
    "    return fig\n",
    "\n",
    "fig = bias_diff(SPATH+'figS6d_data.npz', figsize=(1.3,1.3));\n",
    "plt.gca().set_yticks([-4,-2,0,2,4])\n",
    "plt.savefig(SPATH + \"FigS6d.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MQeEW0fwud7"
   },
   "source": [
    "### Figure S6e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:54.924739Z",
     "start_time": "2020-04-18T01:47:50.735178Z"
    },
    "id": "OqRs-kTlwud7"
   },
   "outputs": [],
   "source": [
    "outData = getMouse(\"CSHL_003\", 5)\n",
    "\n",
    "# Collect data from manually determined training period\n",
    "_start  = np.where(outData['date'] >= '2019-04-30')[0][0]\n",
    "_end    = np.where(outData['date'] >= '2019-05-03')[0][0]\n",
    "new_dat = psy.trim(outData, START=_start, END=_end)\n",
    "\n",
    "# Compute\n",
    "probL_bound = np.where(new_dat['probL'][1:] - new_dat['probL'][:-1] != 0)[0] + 1\n",
    "old_dayLength = new_dat['dayLength']\n",
    "new_dat['dayLength'] = np.hstack((probL_bound[:1], np.diff(probL_bound)))\n",
    "\n",
    "weights = {'bias' : 1, 'cL' : 1, 'cR' : 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**5, 2**-5., 2**-5.]\n",
    "  }\n",
    "optList = ['sigma']#, 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat, 'old_dayLength': old_dayLength}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS6e_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:55.574446Z",
     "start_time": "2020-04-18T01:48:54.927119Z"
    },
    "id": "4xnplxitwud_"
   },
   "outputs": [],
   "source": [
    "fig = bias_diff(SPATH+'figS6e_data.npz', figsize=(1.3,1.3));\n",
    "plt.gca().set_yticks([-4,-2,0,2,4])\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.savefig(SPATH + \"FigS6e.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QHkH1O81wueB"
   },
   "source": [
    "### Figure S6f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:55.632958Z",
     "start_time": "2020-04-18T01:48:55.576832Z"
    },
    "id": "YiZwvskCwueB"
   },
   "outputs": [],
   "source": [
    "def max_bias(bias, side, wL, wR):\n",
    "        \n",
    "    contrasts = np.array([-1., -0.25, -0.125, -0.0625, 0., 0.0625, 0.125, 0.25, 1.])\n",
    "    \n",
    "    p=5\n",
    "    transformed_con = np.tanh(p*np.abs(contrasts))/np.tanh(p)\n",
    "\n",
    "    p_biasL = [.8/4.5]*4 + [1/9] + [.2/4.5]*4    \n",
    "    p_biasR = [.2/4.5]*4 + [1/9] + [.8/4.5]*4\n",
    "    p_biasM = [1/9]*9\n",
    "\n",
    "    w = [wL]*4 + [0] + [wR]*4\n",
    "    correct = [0]*4 + [0] + [1]*4\n",
    "\n",
    "    pL = 1 - (1/(1+np.exp(-(transformed_con*w + bias))))\n",
    "    pCorrect = np.abs(correct - pL)\n",
    "    \n",
    "    if side==\"L\":\n",
    "        pCorrect[4] = pL[4]*0.8 + (1-pL[4])*0.2\n",
    "        expval = np.sum(p_biasL * pCorrect)\n",
    "    \n",
    "    elif side==\"R\":\n",
    "        pCorrect[4] = pL[4]*0.2 + (1-pL[4])*0.8\n",
    "        expval = np.sum(p_biasR * pCorrect)\n",
    "    \n",
    "    elif side==\"M\":\n",
    "        pCorrect[4] = 0.5\n",
    "        expval = np.sum(p_biasM * pCorrect)\n",
    "    \n",
    "    return -expval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:57.445049Z",
     "start_time": "2020-04-18T01:48:55.637573Z"
    },
    "id": "18jG9lWdwueD"
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "dat = np.load(SPATH+'figS6c_data.npz', allow_pickle=True)['dat'].item()\n",
    "start = dat['old_dayLength'][0]\n",
    "\n",
    "optBias = []\n",
    "optReward = []\n",
    "for i in np.arange(start, dat['wMode'].shape[1]):\n",
    "    \n",
    "    if dat['new_dat']['probL'][i] < 0.21: side = 'R'\n",
    "    elif dat['new_dat']['probL'][i] > 0.79: side = 'L'\n",
    "    else: side = 'M'\n",
    "        \n",
    "    res = minimize(max_bias,[0], args=(side, dat['wMode'][1,i], dat['wMode'][2,i]))\n",
    "    optBias += [res.x]\n",
    "    optReward += [-res.fun]\n",
    "\n",
    "print(\"Avg. Reward:\", np.mean(optReward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:58.070451Z",
     "start_time": "2020-04-18T01:48:57.448083Z"
    },
    "id": "HUFB3teswueF"
   },
   "outputs": [],
   "source": [
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat[\"old_dayLength\"],\n",
    "                       errorbar=dat['W_std'], figsize=(2.75,1.3))\n",
    "fig = addBiasBlocks(fig, dat['new_dat']['probL'])\n",
    "\n",
    "plt.plot(np.arange(start, dat['wMode'].shape[1]), optBias, 'k-', lw=2, zorder=10)\n",
    "plt.gca().set_yticks(np.arange(-6, 7,2))\n",
    "plt.gca().set_yticklabels([])\n",
    "plt.gca().set_xticks([750, 1000, 1250])\n",
    "plt.xlim(start, None); plt.ylim(-5.3,5.3)\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS6f.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T01:48:58.292918Z",
     "start_time": "2020-04-18T01:48:58.074129Z"
    },
    "id": "2CGF9p1GwueI"
   },
   "outputs": [],
   "source": [
    "# Actual predicted reward using actual bias weight\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "optReward_pred = []\n",
    "optReward_0bias = []\n",
    "for i in np.arange(start, dat['wMode'].shape[1]):\n",
    "    \n",
    "    if dat['new_dat']['probL'][i] < 0.21: side = 'R'\n",
    "    elif dat['new_dat']['probL'][i] > 0.79: side = 'L'\n",
    "    else: side = 'M'\n",
    "        \n",
    "    optReward_pred += [-max_bias(dat['wMode'][0,i], side, dat['wMode'][1,i], dat['wMode'][2,i])]\n",
    "    optReward_0bias += [-max_bias(0.0, side, dat['wMode'][1,i], dat['wMode'][2,i])]\n",
    "\n",
    "print(\"Predicted Avg. Reward:\", np.mean(optReward_pred))\n",
    "print(\"No Bias Avg. Reward:\", np.mean(optReward_0bias))\n",
    "print(\"Empirical Avg. Reward:\", np.mean(dat['new_dat']['correct'][start:]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1dX_Et4bU7p"
   },
   "source": [
    "## Figure S7 | Example Akrami rat without history regressors\n",
    "\n",
    "Replica of Figure 5, except history regressors are not included in the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2jr9Z-3DrDG"
   },
   "source": [
    "### Figure S7b\n",
    "\n",
    "_15 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T02:04:08.046571Z",
     "start_time": "2020-04-18T01:50:15.385773Z"
    },
    "id": "IuD-DPnXDrDI"
   },
   "outputs": [],
   "source": [
    "outData = getRat(\"W080\")\n",
    "new_dat = psy.trim(outData, START=0, END=12500)\n",
    "\n",
    "weights = {'bias': 1, 's_a': 1, 's_b': 1, 'h': 0, 'c': 0, \"s_avg\": 0}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : [2**-4]*K,\n",
    "  }\n",
    "optList = ['sigma', 'sigDay']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS7b_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T02:04:09.643751Z",
     "start_time": "2020-04-18T02:04:08.049537Z"
    },
    "id": "9FY9RNYQDrDL"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'figS7b_data.npz', allow_pickle=True)['dat'].item()\n",
    "\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], days=dat['new_dat'][\"dayLength\"], \n",
    "                       errorbar=dat['W_std'], figsize=(4.75,1.4))\n",
    "\n",
    "selected_days = [[2000,2500], [6500,7000], [11000,11500]]\n",
    "for d in selected_days:\n",
    "    plt.plot(d, [-1.3]*2, lw=2, color=\"k\")\n",
    "\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.ylim(-1.45,1.45)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS7b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeKiN7f3DrDO"
   },
   "source": [
    "### Fig S7c-e\n",
    "\n",
    "These subfigures reuse data from Figure 8a, please go run the cell above that creates the file `fig8a_data.npz` to produce Figures S7c-e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dz6vxRMgDrDQ"
   },
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "from scipy.stats import sem\n",
    "\n",
    "outData = np.load(SPATH+'fig8a_data.npz', allow_pickle=True)['new_dat'].item()\n",
    "xval_pL = np.load(SPATH+'fig8a_data.npz', allow_pickle=True)['xval_pL'] \n",
    "outData['xval_pR'] = 1 - xval_pL\n",
    "\n",
    "all_hists = []\n",
    "all_ys = []\n",
    "all_pRs = []\n",
    "\n",
    "selected_days = [[2000,2500], [6500,7000], [11000,11500]]\n",
    "for d in selected_days:\n",
    "    new_dat = psy.trim(outData, START=d[0], END=d[1])\n",
    "\n",
    "    hists = []\n",
    "    ys = []\n",
    "    pRs = []\n",
    "    for h in [-1,1]:\n",
    "        for c in [-1,1]:\n",
    "            for a in [-1,1]:\n",
    "                ind_h = (new_dat['inputs']['h'][:,0] == h)\n",
    "                ind_c = (new_dat['inputs']['c'][:,0] == c)\n",
    "                ind_a = (np.sign(new_dat['s_a'] - new_dat['s_b']) == a)\n",
    "                inds = ind_h * ind_c * ind_a\n",
    "                hists += [[h,c,a]]\n",
    "                ys += [new_dat['y'][inds]]\n",
    "                pRs += [new_dat['xval_pR'][inds]]\n",
    "    \n",
    "    all_hists += [hists]\n",
    "    all_ys += [ys]\n",
    "    all_pRs += [pRs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eZR_KjQ2DrDT"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "def colorFader(c1,c2,mix=0):\n",
    "    c1=np.array(mpl.colors.to_rgb(c1))\n",
    "    c2=np.array(mpl.colors.to_rgb(c2))\n",
    "    w =np.array(mpl.colors.to_rgb(\"white\"))\n",
    "    if mix <= 0.5:\n",
    "        return mpl.colors.to_hex((1-mix*2)*c1 + mix*2*w)\n",
    "    else:\n",
    "        return mpl.colors.to_hex((1-(mix-0.5)*2)*w + (mix-0.5)*2*c2)\n",
    "\n",
    "def cF(mix):\n",
    "    return colorFader(colors['s2'],colors['s1'],mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOtq3Yc0DrDW"
   },
   "outputs": [],
   "source": [
    "diff = 0.19\n",
    "rad = 0.45 \n",
    "cm = plt.get_cmap('RdBu_r')\n",
    "\n",
    "for d in range(len(selected_days)):\n",
    "    plt.figure(figsize=(0.75,1.5))\n",
    "    avg = [np.average(i) for i in all_ys[d]]\n",
    "    avg_pR = [np.average(i) for i in all_pRs[d]]\n",
    "\n",
    "    for i in range(len(avg)):\n",
    "        h = all_hists[d][i][0]\n",
    "        c = all_hists[d][i][1]\n",
    "        a = all_hists[d][i][2]\n",
    "        x = a/2\n",
    "        y = h + c/2\n",
    "\n",
    "        plt.text(x-diff, y+diff, int(np.round(avg_pR[i]*100)),\n",
    "                 ha=\"center\", va=\"center\", fontsize=10, zorder=i+1)\n",
    "        t1 = plt.Polygon([[x-rad,y-rad],[x-rad,y+rad],[x+rad,y+rad]], \n",
    "                         facecolor=cF(avg_pR[i]), edgecolor=\"k\", lw=0, zorder=i)\n",
    "        plt.gca().add_patch(t1)\n",
    "\n",
    "        plt.text(x+diff, y-1.5*diff, int(np.round(avg[i]*100)),\n",
    "                 ha=\"center\", va=\"center\", fontsize=10, zorder = i+11)\n",
    "        t2 = plt.Polygon([[x-rad,y-rad],[x+rad,y-rad],[x+rad,y+rad]], \n",
    "                         facecolor=cF(avg[i]), edgecolor=\"k\", lw=0.5, zorder = i+10)\n",
    "        plt.gca().add_patch(t2)\n",
    "        \n",
    "    plt.ylim(-2,2)\n",
    "    plt.xlim(-1,1)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_visible(False)\n",
    "    plt.gca().spines['bottom'].set_visible(False)\n",
    "    plt.gca().set_xticks([])\n",
    "    plt.gca().set_yticks([])\n",
    "\n",
    "    plt.subplots_adjust(0,0,1,1) \n",
    "    plt.savefig(SPATH + \"FigS7cde_\" + str(d) + \".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNm7cB7FWiIy"
   },
   "source": [
    "## Figure S8 | Modeling the Akrami human subjects with the Previous Choice and Previous Answer weights\n",
    "\n",
    "**(A)** Refit model from Figure 6b, with history regressor weights\n",
    "\n",
    "**(B)** Refit models from Figure 6c, with history regressor weights (showing only those weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SiTnMhvgffq"
   },
   "source": [
    "### Figure S8a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:21:44.230480Z",
     "start_time": "2020-04-18T21:20:15.144756Z"
    },
    "id": "rcsbxcfLgffq"
   },
   "outputs": [],
   "source": [
    "new_dat = getHuman(6)\n",
    "\n",
    "prev_choice = np.hstack(([0], new_dat['y'][:-1]*2 - 1)).reshape(-1,1)\n",
    "prev_answer = np.hstack(([0], new_dat['answer'][:-1]*2 - 1)).reshape(-1,1)\n",
    "new_dat['inputs']['c'] = prev_choice\n",
    "new_dat['inputs']['h'] = prev_answer\n",
    "\n",
    "# Compute\n",
    "weights = {'bias': 1, 's_a': 1, 's_b': 1, 's_avg': 1, 'h': 1, 'c': 1}\n",
    "K = np.sum([weights[i] for i in weights.keys()])\n",
    "hyper_guess = {\n",
    " 'sigma'   : [2**-5]*K,\n",
    " 'sigInit' : 2**5,\n",
    " 'sigDay'  : None\n",
    "  }\n",
    "optList = ['sigma']\n",
    "\n",
    "hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "       'weights' : weights, 'new_dat' : new_dat}\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS8a_data.npz', dat=dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:21:44.879328Z",
     "start_time": "2020-04-18T21:21:44.233177Z"
    },
    "id": "-P8uPFDNgffu"
   },
   "outputs": [],
   "source": [
    "dat = np.load(SPATH+'figS8a_data.npz', allow_pickle=True)['dat'].item()\n",
    "fig = psy.plot_weights(dat['wMode'], dat['weights'], errorbar=dat['W_std'], figsize=(4.75,1.4))\n",
    "\n",
    "plt.xlabel(None); plt.ylabel(None)\n",
    "plt.gca().set_xticks([0,500,1000,1500,2000])\n",
    "plt.gca().set_yticks(np.arange(-2, 3,2))\n",
    "plt.xlim(0, 1900); plt.ylim(-3.4, 3.4)\n",
    "\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS8a.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WEztwr3ygffx"
   },
   "source": [
    "### Figure S8b\n",
    "\n",
    "_6 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:28:26.762371Z",
     "start_time": "2020-04-18T21:22:50.545819Z"
    },
    "id": "UVlNuhLngffx"
   },
   "outputs": [],
   "source": [
    "all_dat = []\n",
    "all_subjects = HUMAN_DF[\"subject_id\"].unique()\n",
    "for i, subject in enumerate(all_subjects):\n",
    "    \n",
    "    print(\"\\rProcessing \" + str(i+1) + \" of \" + str(len(all_subjects)), end=\"\")\n",
    "    new_dat = getHuman(subject)\n",
    "\n",
    "    prev_choice = np.hstack(([0], new_dat['y'][:-1]*2 - 1)).reshape(-1,1)\n",
    "    prev_answer = np.hstack(([0], new_dat['answer'][:-1]*2 - 1)).reshape(-1,1)\n",
    "    new_dat['inputs']['c'] = prev_choice\n",
    "    new_dat['inputs']['h'] = prev_answer\n",
    "\n",
    "    # Compute\n",
    "    weights = {'bias': 1, 's_a': 1, 's_b': 1, 's_avg': 1, 'h': 1, 'c': 1}\n",
    "    K = np.sum([weights[i] for i in weights.keys()])\n",
    "    hyper_guess = {\n",
    "     'sigma'   : [2**-5]*K,\n",
    "     'sigInit' : 2**5,\n",
    "     'sigDay'  : None\n",
    "      }\n",
    "    optList = ['sigma']\n",
    "\n",
    "    hyp, evd, wMode, hess_info = psy.hyperOpt(new_dat, hyper_guess, weights, optList)\n",
    "\n",
    "    dat = {'hyp' : hyp, 'evd' : evd, 'wMode' : wMode, 'W_std' : hess_info['W_std'],\n",
    "           'weights' : weights, 'new_dat' : new_dat}\n",
    "    all_dat += [dat]\n",
    "\n",
    "# Save interim result\n",
    "np.savez_compressed(SPATH+'figS8b_data.npz', all_dat=all_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-18T21:28:27.435087Z",
     "start_time": "2020-04-18T21:28:26.764779Z"
    },
    "id": "2GUTq4xegff2"
   },
   "outputs": [],
   "source": [
    "all_dat = np.load(SPATH+'figS8b_data.npz', allow_pickle=True)['all_dat']\n",
    "\n",
    "plt.figure(figsize=(4.75,1.4))\n",
    "for dat in all_dat:\n",
    "\n",
    "    weights = dat['weights']\n",
    "    wMode = dat['wMode']\n",
    "    labels = []\n",
    "    for j in sorted(weights.keys()):\n",
    "        labels += [j]*weights[j]\n",
    "\n",
    "    for i, w in enumerate(labels):\n",
    "        if w in ['h', 'c']:\n",
    "            plt.plot(wMode[i], lw=1.5, alpha=0.5, linestyle='-', c=colors[w], zorder=zorder[w])\n",
    "\n",
    "plt.axhline(0, color=\"black\", linestyle=\"--\", lw=1, alpha=0.5, zorder=0)\n",
    "plt.gca().set_xticks([0,500,1000,1500,2000])\n",
    "plt.gca().set_yticks(np.arange(-2, 3,2))\n",
    "plt.xlim(0, 1900); plt.ylim(-3.4, 3.4)\n",
    "\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.subplots_adjust(0,0,1,1) \n",
    "plt.savefig(SPATH + \"FigS8b.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3sax78Icoaj"
   },
   "source": [
    "#    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "N2E8Peqygff4"
   },
   "source": [
    "# Notebook Versioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "_DozFiOsgff4"
   },
   "source": [
    "**1.1.0** : (November 23, 2020) update following _Neuron_ reviewer feedback\n",
    " - add/replace Figure 5C-E\n",
    " - add Figure 6F\n",
    " - add Figures S2, S5, S6, & S7\n",
    "\n",
    "\n",
    "**1.0.0** : (May 21, 2020) original release"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hy2T21cAgff5"
   },
   "source": [
    "# Download All Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtB9zwi3h_Q9"
   },
   "outputs": [],
   "source": [
    "!zip -r \"all_figures.zip\" . -i \"{SPATH}*.pdf\"\n",
    "import time; time.sleep(10)\n",
    "\n",
    "from google.colab import files\n",
    "files.download(\"all_figures.zip\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "QAHhUULfgfdm",
    "dvHbOKpcgfel",
    "-4DwBkzYgffD",
    "AjpYNikwgffV",
    "N2E8Peqygff4",
    "Hy2T21cAgff5"
   ],
   "name": "PsyTrack_Manuscript_Figures.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
